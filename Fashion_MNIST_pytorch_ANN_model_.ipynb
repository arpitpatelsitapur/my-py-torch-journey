{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyM6Iyt+CB41xGuwkoEuNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpitpatelsitapur/my-py-torch-journey/blob/main/Fashion_MNIST_pytorch_ANN_model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Checking in only 6000 rows of training and 1000 of testing**"
      ],
      "metadata": {
        "id": "Pn2zeoUyW0Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we load MNIST data from keras, there are other methods too.\n",
        "from keras import datasets\n",
        "(X_train, y_train), (X_test, y_test) =datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "5fM5f2TLwPua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7JeFULzvuT1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reshape the arrays to be 2-dimensional\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "y_train = y_train.reshape(y_train.shape[0], -1)\n",
        "y_test = y_test.reshape(y_test.shape[0], -1)\n",
        "\n",
        "# convert into Dataframe\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_test = pd.DataFrame(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "pO9snHVlwNQP",
        "outputId": "c9b8e465-4140-4e53-f2e6-bf6b387ba48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
              "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "1    0    0    0    0    0    1    0    0    0    0  ...  119  114  130   76   \n",
              "2    0    0    0    0    0    0    0    0    0   22  ...    0    0    1    0   \n",
              "3    0    0    0    0    0    0    0    0   33   96  ...    0    0    0    0   \n",
              "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "\n",
              "   778  779  780  781  782  783  \n",
              "0    0    0    0    0    0    0  \n",
              "1    0    0    0    0    0    0  \n",
              "2    0    0    0    0    0    0  \n",
              "3    0    0    0    0    0    0  \n",
              "4    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a37252-a55e-4feb-8e09-960c00dc8495\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>119</td>\n",
              "      <td>114</td>\n",
              "      <td>130</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>96</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a37252-a55e-4feb-8e09-960c00dc8495')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a37252-a55e-4feb-8e09-960c00dc8495 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a37252-a55e-4feb-8e09-960c00dc8495');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f674a67-be9d-44b8-8e8b-113ce371a10c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f674a67-be9d-44b8-8e8b-113ce371a10c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f674a67-be9d-44b8-8e8b-113ce371a10c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train.shape = \", X_train.shape)\n",
        "print(\"X_test.shape = \", X_test.shape)\n",
        "print(\"-\"*100)\n",
        "print(\"Keeping only 6000 in training and 1000 for testing.\")\n",
        "X_train=X_train.head(6000)\n",
        "X_test=X_test.head(1000)\n",
        "y_train=y_train.head(6000)\n",
        "y_test=y_test.head(1000)\n",
        "print(\"-\"*100)\n",
        "print(\"X_train.shape = \", X_train.shape)\n",
        "print(\"X_test.shape = \", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yfytyOqy6Wj",
        "outputId": "886599a1-0c29-4a71-cc6f-80f0d0f23768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape =  (60000, 784)\n",
            "X_test.shape =  (10000, 784)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Keeping only 6000 in training and 1000 for testing.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "X_train.shape =  (6000, 784)\n",
            "X_test.shape =  (1000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if running first time, u need to install torchinfo\n",
        "# !pip install torchinfo"
      ],
      "metadata": {
        "id": "ZaQ-UyMY1dms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZx3Q57Ry6S6",
        "outputId": "a8d990b5-9d0c-40ae-9763-2ef8fb37ad57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b4026b69950>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "Vtk9WnY6y6Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_t.shape = {X_train_t.shape}, y_train_t.shape = {y_train_t.shape}\")\n",
        "print(f\"X_test_t.shape = {X_test_t.shape}, y_test_t.shape = {y_test_t.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWTqtYRBy6M7",
        "outputId": "982787f9-0d1a-4a4a-8601-618647b47453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_t.shape = torch.Size([6000, 784]), y_train_t.shape = torch.Size([6000, 1])\n",
            "X_test_t.shape = torch.Size([1000, 784]), y_test_t.shape = torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define datset and dataloader\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class custom_dataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "    self.n_samples=X.shape[0]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.X[index],self.y[index]\n",
        "\n",
        "train_dataset=custom_dataset(X_train_t,y_train_t)\n",
        "test_dataset=custom_dataset(X_test_t,y_test_t)\n",
        "\n",
        "train_loader=DataLoader(dataset=train_dataset,batch_size=150,shuffle=True)\n",
        "test_loader=DataLoader(dataset=test_dataset,batch_size=150,shuffle=True)\n",
        "\n",
        "for batch_X,batch_y in test_loader:\n",
        "  # print(batch_X)\n",
        "  # print(batch_y)\n",
        "  print(f\"batch_X.shape = {batch_X.shape}, batch_y.shape = {batch_y.shape}\")\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmEfxyBJy6Jy",
        "outputId": "d7c441aa-8d87-41b1-af2d-069d2dae1108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([150, 784]), batch_y.shape = torch.Size([150, 1])\n",
            "--------------------------------------------------\n",
            "batch_X.shape = torch.Size([100, 784]), batch_y.shape = torch.Size([100, 1])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## **ANN model structure**\n",
        "# - input layer (784)\n",
        "# - 2 hidden layer (each 128)\n",
        "# - 1 output layer\n",
        "# - relu in hidden layers\n",
        "# - softmax in output layer\n",
        "\n",
        "# Define model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))      # hidden layer1 with ReLU\n",
        "        x = torch.relu(self.fc2(x))      # hidden layer1 with ReLU\n",
        "        x = self.fc3(x)  # output layer (remove softmax, CrossEntropyLoss includes it)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tqUKLvK3y6GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 128\n",
        "output_size = 10  # 10 classes for Fashion MNIST\n",
        "num_epochs = 50\n",
        "lr = 0.001\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axwj84Sqy5-n",
        "outputId": "fd171dbf-b790-495d-f938-5219bfe97873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "SimpleNN                                 --\n",
              "├─Linear: 1-1                            100,480\n",
              "├─Linear: 1-2                            16,512\n",
              "├─Linear: 1-3                            1,290\n",
              "=================================================================\n",
              "Total params: 118,282\n",
              "Trainable params: 118,282\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training (one batch of dataset per epoch)\n",
        "for epoch in range(num_epochs):\n",
        "    batch_no=1\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        # forward pass\n",
        "        outputs = model(batch_X)\n",
        "        # loss calculation\n",
        "        l = loss(outputs, batch_y.squeeze(1))\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        # updating grads\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch {batch_no}, Loss: {l.item():.4f}\")\n",
        "        batch_no=batch_no+1\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrAps-oo3zL0",
        "outputId": "dc93b252-bf4b-45ec-d692-d73262b6aced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Batch 1, Loss: 18.9197\n",
            "Epoch [1/50], Batch 2, Loss: 15.6825\n",
            "Epoch [1/50], Batch 3, Loss: 13.7244\n",
            "Epoch [1/50], Batch 4, Loss: 17.0933\n",
            "Epoch [1/50], Batch 5, Loss: 12.7258\n",
            "Epoch [1/50], Batch 6, Loss: 10.8626\n",
            "Epoch [1/50], Batch 7, Loss: 9.7363\n",
            "Epoch [1/50], Batch 8, Loss: 6.4689\n",
            "Epoch [1/50], Batch 9, Loss: 5.6945\n",
            "Epoch [1/50], Batch 10, Loss: 4.1110\n",
            "Epoch [1/50], Batch 11, Loss: 3.8076\n",
            "Epoch [1/50], Batch 12, Loss: 3.6110\n",
            "Epoch [1/50], Batch 13, Loss: 1.7109\n",
            "Epoch [1/50], Batch 14, Loss: 2.4474\n",
            "Epoch [1/50], Batch 15, Loss: 2.7614\n",
            "Epoch [1/50], Batch 16, Loss: 2.1721\n",
            "Epoch [1/50], Batch 17, Loss: 1.0055\n",
            "Epoch [1/50], Batch 18, Loss: 2.1075\n",
            "Epoch [1/50], Batch 19, Loss: 2.0032\n",
            "Epoch [1/50], Batch 20, Loss: 1.7227\n",
            "Epoch [1/50], Batch 21, Loss: 1.8280\n",
            "Epoch [1/50], Batch 22, Loss: 1.6201\n",
            "Epoch [1/50], Batch 23, Loss: 1.1484\n",
            "Epoch [1/50], Batch 24, Loss: 1.1362\n",
            "Epoch [1/50], Batch 25, Loss: 1.6635\n",
            "Epoch [1/50], Batch 26, Loss: 1.0426\n",
            "Epoch [1/50], Batch 27, Loss: 0.9423\n",
            "Epoch [1/50], Batch 28, Loss: 1.1852\n",
            "Epoch [1/50], Batch 29, Loss: 0.8529\n",
            "Epoch [1/50], Batch 30, Loss: 1.0780\n",
            "Epoch [1/50], Batch 31, Loss: 1.1895\n",
            "Epoch [1/50], Batch 32, Loss: 1.1058\n",
            "Epoch [1/50], Batch 33, Loss: 0.9182\n",
            "Epoch [1/50], Batch 34, Loss: 0.9710\n",
            "Epoch [1/50], Batch 35, Loss: 0.8113\n",
            "Epoch [1/50], Batch 36, Loss: 1.0693\n",
            "Epoch [1/50], Batch 37, Loss: 0.7302\n",
            "Epoch [1/50], Batch 38, Loss: 0.8649\n",
            "Epoch [1/50], Batch 39, Loss: 1.2111\n",
            "Epoch [1/50], Batch 40, Loss: 1.0083\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [2/50], Batch 1, Loss: 0.7310\n",
            "Epoch [2/50], Batch 2, Loss: 0.6684\n",
            "Epoch [2/50], Batch 3, Loss: 0.6491\n",
            "Epoch [2/50], Batch 4, Loss: 0.5684\n",
            "Epoch [2/50], Batch 5, Loss: 0.7249\n",
            "Epoch [2/50], Batch 6, Loss: 0.7185\n",
            "Epoch [2/50], Batch 7, Loss: 0.7818\n",
            "Epoch [2/50], Batch 8, Loss: 0.8353\n",
            "Epoch [2/50], Batch 9, Loss: 0.6272\n",
            "Epoch [2/50], Batch 10, Loss: 0.8287\n",
            "Epoch [2/50], Batch 11, Loss: 0.6137\n",
            "Epoch [2/50], Batch 12, Loss: 0.7190\n",
            "Epoch [2/50], Batch 13, Loss: 0.7433\n",
            "Epoch [2/50], Batch 14, Loss: 0.6600\n",
            "Epoch [2/50], Batch 15, Loss: 0.5500\n",
            "Epoch [2/50], Batch 16, Loss: 0.6338\n",
            "Epoch [2/50], Batch 17, Loss: 0.6178\n",
            "Epoch [2/50], Batch 18, Loss: 0.6337\n",
            "Epoch [2/50], Batch 19, Loss: 0.6155\n",
            "Epoch [2/50], Batch 20, Loss: 0.5951\n",
            "Epoch [2/50], Batch 21, Loss: 0.9013\n",
            "Epoch [2/50], Batch 22, Loss: 0.6417\n",
            "Epoch [2/50], Batch 23, Loss: 0.5073\n",
            "Epoch [2/50], Batch 24, Loss: 0.7581\n",
            "Epoch [2/50], Batch 25, Loss: 0.6404\n",
            "Epoch [2/50], Batch 26, Loss: 0.6515\n",
            "Epoch [2/50], Batch 27, Loss: 0.7449\n",
            "Epoch [2/50], Batch 28, Loss: 0.4580\n",
            "Epoch [2/50], Batch 29, Loss: 0.7788\n",
            "Epoch [2/50], Batch 30, Loss: 0.6943\n",
            "Epoch [2/50], Batch 31, Loss: 0.6586\n",
            "Epoch [2/50], Batch 32, Loss: 0.5870\n",
            "Epoch [2/50], Batch 33, Loss: 0.5672\n",
            "Epoch [2/50], Batch 34, Loss: 0.5662\n",
            "Epoch [2/50], Batch 35, Loss: 0.6062\n",
            "Epoch [2/50], Batch 36, Loss: 0.4931\n",
            "Epoch [2/50], Batch 37, Loss: 0.4303\n",
            "Epoch [2/50], Batch 38, Loss: 0.7273\n",
            "Epoch [2/50], Batch 39, Loss: 0.3198\n",
            "Epoch [2/50], Batch 40, Loss: 0.5807\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [3/50], Batch 1, Loss: 0.6243\n",
            "Epoch [3/50], Batch 2, Loss: 0.4395\n",
            "Epoch [3/50], Batch 3, Loss: 0.5406\n",
            "Epoch [3/50], Batch 4, Loss: 0.4786\n",
            "Epoch [3/50], Batch 5, Loss: 0.4555\n",
            "Epoch [3/50], Batch 6, Loss: 0.5296\n",
            "Epoch [3/50], Batch 7, Loss: 0.4595\n",
            "Epoch [3/50], Batch 8, Loss: 0.4753\n",
            "Epoch [3/50], Batch 9, Loss: 0.4686\n",
            "Epoch [3/50], Batch 10, Loss: 0.4818\n",
            "Epoch [3/50], Batch 11, Loss: 0.5429\n",
            "Epoch [3/50], Batch 12, Loss: 0.6176\n",
            "Epoch [3/50], Batch 13, Loss: 0.4659\n",
            "Epoch [3/50], Batch 14, Loss: 0.4287\n",
            "Epoch [3/50], Batch 15, Loss: 0.4963\n",
            "Epoch [3/50], Batch 16, Loss: 0.5470\n",
            "Epoch [3/50], Batch 17, Loss: 0.5707\n",
            "Epoch [3/50], Batch 18, Loss: 0.7455\n",
            "Epoch [3/50], Batch 19, Loss: 0.5026\n",
            "Epoch [3/50], Batch 20, Loss: 0.4243\n",
            "Epoch [3/50], Batch 21, Loss: 0.5528\n",
            "Epoch [3/50], Batch 22, Loss: 0.4866\n",
            "Epoch [3/50], Batch 23, Loss: 0.3568\n",
            "Epoch [3/50], Batch 24, Loss: 0.5491\n",
            "Epoch [3/50], Batch 25, Loss: 0.6726\n",
            "Epoch [3/50], Batch 26, Loss: 0.5930\n",
            "Epoch [3/50], Batch 27, Loss: 0.3966\n",
            "Epoch [3/50], Batch 28, Loss: 0.5612\n",
            "Epoch [3/50], Batch 29, Loss: 0.5950\n",
            "Epoch [3/50], Batch 30, Loss: 0.6661\n",
            "Epoch [3/50], Batch 31, Loss: 0.5431\n",
            "Epoch [3/50], Batch 32, Loss: 0.6096\n",
            "Epoch [3/50], Batch 33, Loss: 0.4554\n",
            "Epoch [3/50], Batch 34, Loss: 0.7374\n",
            "Epoch [3/50], Batch 35, Loss: 0.5781\n",
            "Epoch [3/50], Batch 36, Loss: 0.6519\n",
            "Epoch [3/50], Batch 37, Loss: 0.5602\n",
            "Epoch [3/50], Batch 38, Loss: 0.6399\n",
            "Epoch [3/50], Batch 39, Loss: 0.4677\n",
            "Epoch [3/50], Batch 40, Loss: 0.6009\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [4/50], Batch 1, Loss: 0.5859\n",
            "Epoch [4/50], Batch 2, Loss: 0.6228\n",
            "Epoch [4/50], Batch 3, Loss: 0.5756\n",
            "Epoch [4/50], Batch 4, Loss: 0.6810\n",
            "Epoch [4/50], Batch 5, Loss: 0.4350\n",
            "Epoch [4/50], Batch 6, Loss: 0.4173\n",
            "Epoch [4/50], Batch 7, Loss: 0.3842\n",
            "Epoch [4/50], Batch 8, Loss: 0.5720\n",
            "Epoch [4/50], Batch 9, Loss: 0.5769\n",
            "Epoch [4/50], Batch 10, Loss: 0.5401\n",
            "Epoch [4/50], Batch 11, Loss: 0.4746\n",
            "Epoch [4/50], Batch 12, Loss: 0.5269\n",
            "Epoch [4/50], Batch 13, Loss: 0.5532\n",
            "Epoch [4/50], Batch 14, Loss: 0.5930\n",
            "Epoch [4/50], Batch 15, Loss: 0.4629\n",
            "Epoch [4/50], Batch 16, Loss: 0.6751\n",
            "Epoch [4/50], Batch 17, Loss: 0.4786\n",
            "Epoch [4/50], Batch 18, Loss: 0.3802\n",
            "Epoch [4/50], Batch 19, Loss: 0.3906\n",
            "Epoch [4/50], Batch 20, Loss: 0.4267\n",
            "Epoch [4/50], Batch 21, Loss: 0.4932\n",
            "Epoch [4/50], Batch 22, Loss: 0.4608\n",
            "Epoch [4/50], Batch 23, Loss: 0.3968\n",
            "Epoch [4/50], Batch 24, Loss: 0.4959\n",
            "Epoch [4/50], Batch 25, Loss: 0.3768\n",
            "Epoch [4/50], Batch 26, Loss: 0.4871\n",
            "Epoch [4/50], Batch 27, Loss: 0.4703\n",
            "Epoch [4/50], Batch 28, Loss: 0.4382\n",
            "Epoch [4/50], Batch 29, Loss: 0.5222\n",
            "Epoch [4/50], Batch 30, Loss: 0.4155\n",
            "Epoch [4/50], Batch 31, Loss: 0.5334\n",
            "Epoch [4/50], Batch 32, Loss: 0.3087\n",
            "Epoch [4/50], Batch 33, Loss: 0.4545\n",
            "Epoch [4/50], Batch 34, Loss: 0.4823\n",
            "Epoch [4/50], Batch 35, Loss: 0.4862\n",
            "Epoch [4/50], Batch 36, Loss: 0.3788\n",
            "Epoch [4/50], Batch 37, Loss: 0.4088\n",
            "Epoch [4/50], Batch 38, Loss: 0.5000\n",
            "Epoch [4/50], Batch 39, Loss: 0.3927\n",
            "Epoch [4/50], Batch 40, Loss: 0.5281\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [5/50], Batch 1, Loss: 0.4158\n",
            "Epoch [5/50], Batch 2, Loss: 0.4079\n",
            "Epoch [5/50], Batch 3, Loss: 0.4317\n",
            "Epoch [5/50], Batch 4, Loss: 0.5331\n",
            "Epoch [5/50], Batch 5, Loss: 0.3396\n",
            "Epoch [5/50], Batch 6, Loss: 0.4692\n",
            "Epoch [5/50], Batch 7, Loss: 0.2845\n",
            "Epoch [5/50], Batch 8, Loss: 0.3929\n",
            "Epoch [5/50], Batch 9, Loss: 0.3774\n",
            "Epoch [5/50], Batch 10, Loss: 0.3792\n",
            "Epoch [5/50], Batch 11, Loss: 0.4560\n",
            "Epoch [5/50], Batch 12, Loss: 0.5145\n",
            "Epoch [5/50], Batch 13, Loss: 0.4318\n",
            "Epoch [5/50], Batch 14, Loss: 0.3266\n",
            "Epoch [5/50], Batch 15, Loss: 0.4724\n",
            "Epoch [5/50], Batch 16, Loss: 0.2861\n",
            "Epoch [5/50], Batch 17, Loss: 0.3803\n",
            "Epoch [5/50], Batch 18, Loss: 0.5093\n",
            "Epoch [5/50], Batch 19, Loss: 0.4642\n",
            "Epoch [5/50], Batch 20, Loss: 0.3178\n",
            "Epoch [5/50], Batch 21, Loss: 0.4262\n",
            "Epoch [5/50], Batch 22, Loss: 0.4752\n",
            "Epoch [5/50], Batch 23, Loss: 0.4864\n",
            "Epoch [5/50], Batch 24, Loss: 0.4309\n",
            "Epoch [5/50], Batch 25, Loss: 0.4241\n",
            "Epoch [5/50], Batch 26, Loss: 0.3755\n",
            "Epoch [5/50], Batch 27, Loss: 0.5566\n",
            "Epoch [5/50], Batch 28, Loss: 0.5315\n",
            "Epoch [5/50], Batch 29, Loss: 0.4441\n",
            "Epoch [5/50], Batch 30, Loss: 0.4532\n",
            "Epoch [5/50], Batch 31, Loss: 0.3999\n",
            "Epoch [5/50], Batch 32, Loss: 0.5844\n",
            "Epoch [5/50], Batch 33, Loss: 0.3124\n",
            "Epoch [5/50], Batch 34, Loss: 0.4890\n",
            "Epoch [5/50], Batch 35, Loss: 0.4703\n",
            "Epoch [5/50], Batch 36, Loss: 0.4686\n",
            "Epoch [5/50], Batch 37, Loss: 0.4766\n",
            "Epoch [5/50], Batch 38, Loss: 0.5090\n",
            "Epoch [5/50], Batch 39, Loss: 0.3919\n",
            "Epoch [5/50], Batch 40, Loss: 0.5417\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [6/50], Batch 1, Loss: 0.5467\n",
            "Epoch [6/50], Batch 2, Loss: 0.3962\n",
            "Epoch [6/50], Batch 3, Loss: 0.3700\n",
            "Epoch [6/50], Batch 4, Loss: 0.4145\n",
            "Epoch [6/50], Batch 5, Loss: 0.6319\n",
            "Epoch [6/50], Batch 6, Loss: 0.4396\n",
            "Epoch [6/50], Batch 7, Loss: 0.3800\n",
            "Epoch [6/50], Batch 8, Loss: 0.3626\n",
            "Epoch [6/50], Batch 9, Loss: 0.4047\n",
            "Epoch [6/50], Batch 10, Loss: 0.4197\n",
            "Epoch [6/50], Batch 11, Loss: 0.3281\n",
            "Epoch [6/50], Batch 12, Loss: 0.3535\n",
            "Epoch [6/50], Batch 13, Loss: 0.6216\n",
            "Epoch [6/50], Batch 14, Loss: 0.4765\n",
            "Epoch [6/50], Batch 15, Loss: 0.3554\n",
            "Epoch [6/50], Batch 16, Loss: 0.4031\n",
            "Epoch [6/50], Batch 17, Loss: 0.4292\n",
            "Epoch [6/50], Batch 18, Loss: 0.5763\n",
            "Epoch [6/50], Batch 19, Loss: 0.4336\n",
            "Epoch [6/50], Batch 20, Loss: 0.3906\n",
            "Epoch [6/50], Batch 21, Loss: 0.6300\n",
            "Epoch [6/50], Batch 22, Loss: 0.3935\n",
            "Epoch [6/50], Batch 23, Loss: 0.3192\n",
            "Epoch [6/50], Batch 24, Loss: 0.3522\n",
            "Epoch [6/50], Batch 25, Loss: 0.3707\n",
            "Epoch [6/50], Batch 26, Loss: 0.4142\n",
            "Epoch [6/50], Batch 27, Loss: 0.3446\n",
            "Epoch [6/50], Batch 28, Loss: 0.6132\n",
            "Epoch [6/50], Batch 29, Loss: 0.3083\n",
            "Epoch [6/50], Batch 30, Loss: 0.5094\n",
            "Epoch [6/50], Batch 31, Loss: 0.3859\n",
            "Epoch [6/50], Batch 32, Loss: 0.5539\n",
            "Epoch [6/50], Batch 33, Loss: 0.3452\n",
            "Epoch [6/50], Batch 34, Loss: 0.4400\n",
            "Epoch [6/50], Batch 35, Loss: 0.4892\n",
            "Epoch [6/50], Batch 36, Loss: 0.3406\n",
            "Epoch [6/50], Batch 37, Loss: 0.3269\n",
            "Epoch [6/50], Batch 38, Loss: 0.3972\n",
            "Epoch [6/50], Batch 39, Loss: 0.3717\n",
            "Epoch [6/50], Batch 40, Loss: 0.3902\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [7/50], Batch 1, Loss: 0.4138\n",
            "Epoch [7/50], Batch 2, Loss: 0.3474\n",
            "Epoch [7/50], Batch 3, Loss: 0.3413\n",
            "Epoch [7/50], Batch 4, Loss: 0.3804\n",
            "Epoch [7/50], Batch 5, Loss: 0.3825\n",
            "Epoch [7/50], Batch 6, Loss: 0.2971\n",
            "Epoch [7/50], Batch 7, Loss: 0.3390\n",
            "Epoch [7/50], Batch 8, Loss: 0.4631\n",
            "Epoch [7/50], Batch 9, Loss: 0.2871\n",
            "Epoch [7/50], Batch 10, Loss: 0.3447\n",
            "Epoch [7/50], Batch 11, Loss: 0.3559\n",
            "Epoch [7/50], Batch 12, Loss: 0.3840\n",
            "Epoch [7/50], Batch 13, Loss: 0.2605\n",
            "Epoch [7/50], Batch 14, Loss: 0.3066\n",
            "Epoch [7/50], Batch 15, Loss: 0.3708\n",
            "Epoch [7/50], Batch 16, Loss: 0.3605\n",
            "Epoch [7/50], Batch 17, Loss: 0.5788\n",
            "Epoch [7/50], Batch 18, Loss: 0.3365\n",
            "Epoch [7/50], Batch 19, Loss: 0.3407\n",
            "Epoch [7/50], Batch 20, Loss: 0.4560\n",
            "Epoch [7/50], Batch 21, Loss: 0.4640\n",
            "Epoch [7/50], Batch 22, Loss: 0.4092\n",
            "Epoch [7/50], Batch 23, Loss: 0.5166\n",
            "Epoch [7/50], Batch 24, Loss: 0.2995\n",
            "Epoch [7/50], Batch 25, Loss: 0.3476\n",
            "Epoch [7/50], Batch 26, Loss: 0.3673\n",
            "Epoch [7/50], Batch 27, Loss: 0.3339\n",
            "Epoch [7/50], Batch 28, Loss: 0.4171\n",
            "Epoch [7/50], Batch 29, Loss: 0.4293\n",
            "Epoch [7/50], Batch 30, Loss: 0.3448\n",
            "Epoch [7/50], Batch 31, Loss: 0.3405\n",
            "Epoch [7/50], Batch 32, Loss: 0.3827\n",
            "Epoch [7/50], Batch 33, Loss: 0.4114\n",
            "Epoch [7/50], Batch 34, Loss: 0.4530\n",
            "Epoch [7/50], Batch 35, Loss: 0.5237\n",
            "Epoch [7/50], Batch 36, Loss: 0.4893\n",
            "Epoch [7/50], Batch 37, Loss: 0.3883\n",
            "Epoch [7/50], Batch 38, Loss: 0.4422\n",
            "Epoch [7/50], Batch 39, Loss: 0.4057\n",
            "Epoch [7/50], Batch 40, Loss: 0.3730\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [8/50], Batch 1, Loss: 0.3886\n",
            "Epoch [8/50], Batch 2, Loss: 0.3613\n",
            "Epoch [8/50], Batch 3, Loss: 0.3290\n",
            "Epoch [8/50], Batch 4, Loss: 0.2598\n",
            "Epoch [8/50], Batch 5, Loss: 0.3049\n",
            "Epoch [8/50], Batch 6, Loss: 0.3397\n",
            "Epoch [8/50], Batch 7, Loss: 0.3621\n",
            "Epoch [8/50], Batch 8, Loss: 0.4365\n",
            "Epoch [8/50], Batch 9, Loss: 0.3169\n",
            "Epoch [8/50], Batch 10, Loss: 0.3760\n",
            "Epoch [8/50], Batch 11, Loss: 0.3409\n",
            "Epoch [8/50], Batch 12, Loss: 0.4877\n",
            "Epoch [8/50], Batch 13, Loss: 0.3108\n",
            "Epoch [8/50], Batch 14, Loss: 0.3584\n",
            "Epoch [8/50], Batch 15, Loss: 0.2505\n",
            "Epoch [8/50], Batch 16, Loss: 0.4112\n",
            "Epoch [8/50], Batch 17, Loss: 0.2799\n",
            "Epoch [8/50], Batch 18, Loss: 0.2999\n",
            "Epoch [8/50], Batch 19, Loss: 0.3322\n",
            "Epoch [8/50], Batch 20, Loss: 0.3731\n",
            "Epoch [8/50], Batch 21, Loss: 0.3403\n",
            "Epoch [8/50], Batch 22, Loss: 0.3232\n",
            "Epoch [8/50], Batch 23, Loss: 0.3644\n",
            "Epoch [8/50], Batch 24, Loss: 0.3629\n",
            "Epoch [8/50], Batch 25, Loss: 0.3678\n",
            "Epoch [8/50], Batch 26, Loss: 0.2993\n",
            "Epoch [8/50], Batch 27, Loss: 0.3275\n",
            "Epoch [8/50], Batch 28, Loss: 0.3262\n",
            "Epoch [8/50], Batch 29, Loss: 0.2854\n",
            "Epoch [8/50], Batch 30, Loss: 0.3191\n",
            "Epoch [8/50], Batch 31, Loss: 0.3827\n",
            "Epoch [8/50], Batch 32, Loss: 0.3120\n",
            "Epoch [8/50], Batch 33, Loss: 0.3954\n",
            "Epoch [8/50], Batch 34, Loss: 0.3840\n",
            "Epoch [8/50], Batch 35, Loss: 0.3400\n",
            "Epoch [8/50], Batch 36, Loss: 0.3572\n",
            "Epoch [8/50], Batch 37, Loss: 0.4068\n",
            "Epoch [8/50], Batch 38, Loss: 0.3051\n",
            "Epoch [8/50], Batch 39, Loss: 0.3719\n",
            "Epoch [8/50], Batch 40, Loss: 0.3155\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [9/50], Batch 1, Loss: 0.2871\n",
            "Epoch [9/50], Batch 2, Loss: 0.2454\n",
            "Epoch [9/50], Batch 3, Loss: 0.2952\n",
            "Epoch [9/50], Batch 4, Loss: 0.2950\n",
            "Epoch [9/50], Batch 5, Loss: 0.2944\n",
            "Epoch [9/50], Batch 6, Loss: 0.4020\n",
            "Epoch [9/50], Batch 7, Loss: 0.2798\n",
            "Epoch [9/50], Batch 8, Loss: 0.3236\n",
            "Epoch [9/50], Batch 9, Loss: 0.2744\n",
            "Epoch [9/50], Batch 10, Loss: 0.2185\n",
            "Epoch [9/50], Batch 11, Loss: 0.2935\n",
            "Epoch [9/50], Batch 12, Loss: 0.3696\n",
            "Epoch [9/50], Batch 13, Loss: 0.3098\n",
            "Epoch [9/50], Batch 14, Loss: 0.3294\n",
            "Epoch [9/50], Batch 15, Loss: 0.2728\n",
            "Epoch [9/50], Batch 16, Loss: 0.4483\n",
            "Epoch [9/50], Batch 17, Loss: 0.3322\n",
            "Epoch [9/50], Batch 18, Loss: 0.3542\n",
            "Epoch [9/50], Batch 19, Loss: 0.2693\n",
            "Epoch [9/50], Batch 20, Loss: 0.4028\n",
            "Epoch [9/50], Batch 21, Loss: 0.4680\n",
            "Epoch [9/50], Batch 22, Loss: 0.3113\n",
            "Epoch [9/50], Batch 23, Loss: 0.2179\n",
            "Epoch [9/50], Batch 24, Loss: 0.3070\n",
            "Epoch [9/50], Batch 25, Loss: 0.3110\n",
            "Epoch [9/50], Batch 26, Loss: 0.3169\n",
            "Epoch [9/50], Batch 27, Loss: 0.2263\n",
            "Epoch [9/50], Batch 28, Loss: 0.2764\n",
            "Epoch [9/50], Batch 29, Loss: 0.4477\n",
            "Epoch [9/50], Batch 30, Loss: 0.3138\n",
            "Epoch [9/50], Batch 31, Loss: 0.2878\n",
            "Epoch [9/50], Batch 32, Loss: 0.3692\n",
            "Epoch [9/50], Batch 33, Loss: 0.3933\n",
            "Epoch [9/50], Batch 34, Loss: 0.3195\n",
            "Epoch [9/50], Batch 35, Loss: 0.4257\n",
            "Epoch [9/50], Batch 36, Loss: 0.4435\n",
            "Epoch [9/50], Batch 37, Loss: 0.2575\n",
            "Epoch [9/50], Batch 38, Loss: 0.4194\n",
            "Epoch [9/50], Batch 39, Loss: 0.3309\n",
            "Epoch [9/50], Batch 40, Loss: 0.4549\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [10/50], Batch 1, Loss: 0.3096\n",
            "Epoch [10/50], Batch 2, Loss: 0.3978\n",
            "Epoch [10/50], Batch 3, Loss: 0.2882\n",
            "Epoch [10/50], Batch 4, Loss: 0.2635\n",
            "Epoch [10/50], Batch 5, Loss: 0.3676\n",
            "Epoch [10/50], Batch 6, Loss: 0.3300\n",
            "Epoch [10/50], Batch 7, Loss: 0.3345\n",
            "Epoch [10/50], Batch 8, Loss: 0.2437\n",
            "Epoch [10/50], Batch 9, Loss: 0.2172\n",
            "Epoch [10/50], Batch 10, Loss: 0.2425\n",
            "Epoch [10/50], Batch 11, Loss: 0.2551\n",
            "Epoch [10/50], Batch 12, Loss: 0.4121\n",
            "Epoch [10/50], Batch 13, Loss: 0.3518\n",
            "Epoch [10/50], Batch 14, Loss: 0.4055\n",
            "Epoch [10/50], Batch 15, Loss: 0.3406\n",
            "Epoch [10/50], Batch 16, Loss: 0.2722\n",
            "Epoch [10/50], Batch 17, Loss: 0.2358\n",
            "Epoch [10/50], Batch 18, Loss: 0.3576\n",
            "Epoch [10/50], Batch 19, Loss: 0.3061\n",
            "Epoch [10/50], Batch 20, Loss: 0.3945\n",
            "Epoch [10/50], Batch 21, Loss: 0.2546\n",
            "Epoch [10/50], Batch 22, Loss: 0.3241\n",
            "Epoch [10/50], Batch 23, Loss: 0.3140\n",
            "Epoch [10/50], Batch 24, Loss: 0.2310\n",
            "Epoch [10/50], Batch 25, Loss: 0.2907\n",
            "Epoch [10/50], Batch 26, Loss: 0.3813\n",
            "Epoch [10/50], Batch 27, Loss: 0.2853\n",
            "Epoch [10/50], Batch 28, Loss: 0.2001\n",
            "Epoch [10/50], Batch 29, Loss: 0.4406\n",
            "Epoch [10/50], Batch 30, Loss: 0.3568\n",
            "Epoch [10/50], Batch 31, Loss: 0.3876\n",
            "Epoch [10/50], Batch 32, Loss: 0.3441\n",
            "Epoch [10/50], Batch 33, Loss: 0.2836\n",
            "Epoch [10/50], Batch 34, Loss: 0.3279\n",
            "Epoch [10/50], Batch 35, Loss: 0.2842\n",
            "Epoch [10/50], Batch 36, Loss: 0.3652\n",
            "Epoch [10/50], Batch 37, Loss: 0.5002\n",
            "Epoch [10/50], Batch 38, Loss: 0.3665\n",
            "Epoch [10/50], Batch 39, Loss: 0.5446\n",
            "Epoch [10/50], Batch 40, Loss: 0.1908\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [11/50], Batch 1, Loss: 0.4238\n",
            "Epoch [11/50], Batch 2, Loss: 0.3561\n",
            "Epoch [11/50], Batch 3, Loss: 0.2975\n",
            "Epoch [11/50], Batch 4, Loss: 0.3121\n",
            "Epoch [11/50], Batch 5, Loss: 0.3785\n",
            "Epoch [11/50], Batch 6, Loss: 0.2978\n",
            "Epoch [11/50], Batch 7, Loss: 0.3495\n",
            "Epoch [11/50], Batch 8, Loss: 0.3481\n",
            "Epoch [11/50], Batch 9, Loss: 0.2514\n",
            "Epoch [11/50], Batch 10, Loss: 0.2152\n",
            "Epoch [11/50], Batch 11, Loss: 0.2957\n",
            "Epoch [11/50], Batch 12, Loss: 0.5120\n",
            "Epoch [11/50], Batch 13, Loss: 0.3894\n",
            "Epoch [11/50], Batch 14, Loss: 0.2883\n",
            "Epoch [11/50], Batch 15, Loss: 0.2581\n",
            "Epoch [11/50], Batch 16, Loss: 0.3630\n",
            "Epoch [11/50], Batch 17, Loss: 0.2445\n",
            "Epoch [11/50], Batch 18, Loss: 0.3130\n",
            "Epoch [11/50], Batch 19, Loss: 0.2815\n",
            "Epoch [11/50], Batch 20, Loss: 0.2692\n",
            "Epoch [11/50], Batch 21, Loss: 0.2874\n",
            "Epoch [11/50], Batch 22, Loss: 0.3350\n",
            "Epoch [11/50], Batch 23, Loss: 0.3376\n",
            "Epoch [11/50], Batch 24, Loss: 0.3013\n",
            "Epoch [11/50], Batch 25, Loss: 0.3882\n",
            "Epoch [11/50], Batch 26, Loss: 0.3521\n",
            "Epoch [11/50], Batch 27, Loss: 0.2895\n",
            "Epoch [11/50], Batch 28, Loss: 0.3391\n",
            "Epoch [11/50], Batch 29, Loss: 0.3115\n",
            "Epoch [11/50], Batch 30, Loss: 0.3698\n",
            "Epoch [11/50], Batch 31, Loss: 0.3132\n",
            "Epoch [11/50], Batch 32, Loss: 0.2899\n",
            "Epoch [11/50], Batch 33, Loss: 0.2629\n",
            "Epoch [11/50], Batch 34, Loss: 0.3739\n",
            "Epoch [11/50], Batch 35, Loss: 0.2953\n",
            "Epoch [11/50], Batch 36, Loss: 0.3164\n",
            "Epoch [11/50], Batch 37, Loss: 0.4903\n",
            "Epoch [11/50], Batch 38, Loss: 0.2332\n",
            "Epoch [11/50], Batch 39, Loss: 0.2762\n",
            "Epoch [11/50], Batch 40, Loss: 0.3206\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [12/50], Batch 1, Loss: 0.2682\n",
            "Epoch [12/50], Batch 2, Loss: 0.4079\n",
            "Epoch [12/50], Batch 3, Loss: 0.2346\n",
            "Epoch [12/50], Batch 4, Loss: 0.2425\n",
            "Epoch [12/50], Batch 5, Loss: 0.2910\n",
            "Epoch [12/50], Batch 6, Loss: 0.3324\n",
            "Epoch [12/50], Batch 7, Loss: 0.2741\n",
            "Epoch [12/50], Batch 8, Loss: 0.1422\n",
            "Epoch [12/50], Batch 9, Loss: 0.3225\n",
            "Epoch [12/50], Batch 10, Loss: 0.2189\n",
            "Epoch [12/50], Batch 11, Loss: 0.3103\n",
            "Epoch [12/50], Batch 12, Loss: 0.2997\n",
            "Epoch [12/50], Batch 13, Loss: 0.3582\n",
            "Epoch [12/50], Batch 14, Loss: 0.2923\n",
            "Epoch [12/50], Batch 15, Loss: 0.2801\n",
            "Epoch [12/50], Batch 16, Loss: 0.3216\n",
            "Epoch [12/50], Batch 17, Loss: 0.2589\n",
            "Epoch [12/50], Batch 18, Loss: 0.2739\n",
            "Epoch [12/50], Batch 19, Loss: 0.2246\n",
            "Epoch [12/50], Batch 20, Loss: 0.3504\n",
            "Epoch [12/50], Batch 21, Loss: 0.3243\n",
            "Epoch [12/50], Batch 22, Loss: 0.2985\n",
            "Epoch [12/50], Batch 23, Loss: 0.2901\n",
            "Epoch [12/50], Batch 24, Loss: 0.3807\n",
            "Epoch [12/50], Batch 25, Loss: 0.2272\n",
            "Epoch [12/50], Batch 26, Loss: 0.2440\n",
            "Epoch [12/50], Batch 27, Loss: 0.3179\n",
            "Epoch [12/50], Batch 28, Loss: 0.2594\n",
            "Epoch [12/50], Batch 29, Loss: 0.2604\n",
            "Epoch [12/50], Batch 30, Loss: 0.3178\n",
            "Epoch [12/50], Batch 31, Loss: 0.2325\n",
            "Epoch [12/50], Batch 32, Loss: 0.2628\n",
            "Epoch [12/50], Batch 33, Loss: 0.2292\n",
            "Epoch [12/50], Batch 34, Loss: 0.3123\n",
            "Epoch [12/50], Batch 35, Loss: 0.3093\n",
            "Epoch [12/50], Batch 36, Loss: 0.4135\n",
            "Epoch [12/50], Batch 37, Loss: 0.2895\n",
            "Epoch [12/50], Batch 38, Loss: 0.3698\n",
            "Epoch [12/50], Batch 39, Loss: 0.2929\n",
            "Epoch [12/50], Batch 40, Loss: 0.2095\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [13/50], Batch 1, Loss: 0.3298\n",
            "Epoch [13/50], Batch 2, Loss: 0.2462\n",
            "Epoch [13/50], Batch 3, Loss: 0.2219\n",
            "Epoch [13/50], Batch 4, Loss: 0.3475\n",
            "Epoch [13/50], Batch 5, Loss: 0.3252\n",
            "Epoch [13/50], Batch 6, Loss: 0.2795\n",
            "Epoch [13/50], Batch 7, Loss: 0.2920\n",
            "Epoch [13/50], Batch 8, Loss: 0.2735\n",
            "Epoch [13/50], Batch 9, Loss: 0.3528\n",
            "Epoch [13/50], Batch 10, Loss: 0.4246\n",
            "Epoch [13/50], Batch 11, Loss: 0.2367\n",
            "Epoch [13/50], Batch 12, Loss: 0.3505\n",
            "Epoch [13/50], Batch 13, Loss: 0.2687\n",
            "Epoch [13/50], Batch 14, Loss: 0.2375\n",
            "Epoch [13/50], Batch 15, Loss: 0.3337\n",
            "Epoch [13/50], Batch 16, Loss: 0.2883\n",
            "Epoch [13/50], Batch 17, Loss: 0.2301\n",
            "Epoch [13/50], Batch 18, Loss: 0.2859\n",
            "Epoch [13/50], Batch 19, Loss: 0.2155\n",
            "Epoch [13/50], Batch 20, Loss: 0.1909\n",
            "Epoch [13/50], Batch 21, Loss: 0.2334\n",
            "Epoch [13/50], Batch 22, Loss: 0.1239\n",
            "Epoch [13/50], Batch 23, Loss: 0.3111\n",
            "Epoch [13/50], Batch 24, Loss: 0.3813\n",
            "Epoch [13/50], Batch 25, Loss: 0.2477\n",
            "Epoch [13/50], Batch 26, Loss: 0.3302\n",
            "Epoch [13/50], Batch 27, Loss: 0.2579\n",
            "Epoch [13/50], Batch 28, Loss: 0.3819\n",
            "Epoch [13/50], Batch 29, Loss: 0.2709\n",
            "Epoch [13/50], Batch 30, Loss: 0.4117\n",
            "Epoch [13/50], Batch 31, Loss: 0.2166\n",
            "Epoch [13/50], Batch 32, Loss: 0.2207\n",
            "Epoch [13/50], Batch 33, Loss: 0.2229\n",
            "Epoch [13/50], Batch 34, Loss: 0.2189\n",
            "Epoch [13/50], Batch 35, Loss: 0.2299\n",
            "Epoch [13/50], Batch 36, Loss: 0.1731\n",
            "Epoch [13/50], Batch 37, Loss: 0.2750\n",
            "Epoch [13/50], Batch 38, Loss: 0.3080\n",
            "Epoch [13/50], Batch 39, Loss: 0.3704\n",
            "Epoch [13/50], Batch 40, Loss: 0.2326\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [14/50], Batch 1, Loss: 0.2420\n",
            "Epoch [14/50], Batch 2, Loss: 0.2710\n",
            "Epoch [14/50], Batch 3, Loss: 0.2289\n",
            "Epoch [14/50], Batch 4, Loss: 0.2210\n",
            "Epoch [14/50], Batch 5, Loss: 0.2670\n",
            "Epoch [14/50], Batch 6, Loss: 0.3335\n",
            "Epoch [14/50], Batch 7, Loss: 0.1802\n",
            "Epoch [14/50], Batch 8, Loss: 0.2123\n",
            "Epoch [14/50], Batch 9, Loss: 0.2098\n",
            "Epoch [14/50], Batch 10, Loss: 0.2568\n",
            "Epoch [14/50], Batch 11, Loss: 0.2573\n",
            "Epoch [14/50], Batch 12, Loss: 0.2180\n",
            "Epoch [14/50], Batch 13, Loss: 0.2496\n",
            "Epoch [14/50], Batch 14, Loss: 0.1992\n",
            "Epoch [14/50], Batch 15, Loss: 0.2832\n",
            "Epoch [14/50], Batch 16, Loss: 0.1551\n",
            "Epoch [14/50], Batch 17, Loss: 0.2747\n",
            "Epoch [14/50], Batch 18, Loss: 0.2394\n",
            "Epoch [14/50], Batch 19, Loss: 0.2715\n",
            "Epoch [14/50], Batch 20, Loss: 0.2938\n",
            "Epoch [14/50], Batch 21, Loss: 0.2689\n",
            "Epoch [14/50], Batch 22, Loss: 0.3120\n",
            "Epoch [14/50], Batch 23, Loss: 0.2655\n",
            "Epoch [14/50], Batch 24, Loss: 0.2109\n",
            "Epoch [14/50], Batch 25, Loss: 0.2783\n",
            "Epoch [14/50], Batch 26, Loss: 0.2826\n",
            "Epoch [14/50], Batch 27, Loss: 0.2597\n",
            "Epoch [14/50], Batch 28, Loss: 0.2552\n",
            "Epoch [14/50], Batch 29, Loss: 0.2287\n",
            "Epoch [14/50], Batch 30, Loss: 0.2413\n",
            "Epoch [14/50], Batch 31, Loss: 0.2285\n",
            "Epoch [14/50], Batch 32, Loss: 0.2954\n",
            "Epoch [14/50], Batch 33, Loss: 0.2684\n",
            "Epoch [14/50], Batch 34, Loss: 0.2777\n",
            "Epoch [14/50], Batch 35, Loss: 0.2261\n",
            "Epoch [14/50], Batch 36, Loss: 0.2304\n",
            "Epoch [14/50], Batch 37, Loss: 0.3005\n",
            "Epoch [14/50], Batch 38, Loss: 0.2724\n",
            "Epoch [14/50], Batch 39, Loss: 0.3018\n",
            "Epoch [14/50], Batch 40, Loss: 0.3620\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [15/50], Batch 1, Loss: 0.2981\n",
            "Epoch [15/50], Batch 2, Loss: 0.1518\n",
            "Epoch [15/50], Batch 3, Loss: 0.2352\n",
            "Epoch [15/50], Batch 4, Loss: 0.3685\n",
            "Epoch [15/50], Batch 5, Loss: 0.1948\n",
            "Epoch [15/50], Batch 6, Loss: 0.2192\n",
            "Epoch [15/50], Batch 7, Loss: 0.2204\n",
            "Epoch [15/50], Batch 8, Loss: 0.2133\n",
            "Epoch [15/50], Batch 9, Loss: 0.2274\n",
            "Epoch [15/50], Batch 10, Loss: 0.2508\n",
            "Epoch [15/50], Batch 11, Loss: 0.1965\n",
            "Epoch [15/50], Batch 12, Loss: 0.3985\n",
            "Epoch [15/50], Batch 13, Loss: 0.1733\n",
            "Epoch [15/50], Batch 14, Loss: 0.2786\n",
            "Epoch [15/50], Batch 15, Loss: 0.2188\n",
            "Epoch [15/50], Batch 16, Loss: 0.3550\n",
            "Epoch [15/50], Batch 17, Loss: 0.3268\n",
            "Epoch [15/50], Batch 18, Loss: 0.1733\n",
            "Epoch [15/50], Batch 19, Loss: 0.2264\n",
            "Epoch [15/50], Batch 20, Loss: 0.3727\n",
            "Epoch [15/50], Batch 21, Loss: 0.2366\n",
            "Epoch [15/50], Batch 22, Loss: 0.3321\n",
            "Epoch [15/50], Batch 23, Loss: 0.2699\n",
            "Epoch [15/50], Batch 24, Loss: 0.1505\n",
            "Epoch [15/50], Batch 25, Loss: 0.2379\n",
            "Epoch [15/50], Batch 26, Loss: 0.3292\n",
            "Epoch [15/50], Batch 27, Loss: 0.2444\n",
            "Epoch [15/50], Batch 28, Loss: 0.2853\n",
            "Epoch [15/50], Batch 29, Loss: 0.1720\n",
            "Epoch [15/50], Batch 30, Loss: 0.3453\n",
            "Epoch [15/50], Batch 31, Loss: 0.2619\n",
            "Epoch [15/50], Batch 32, Loss: 0.2287\n",
            "Epoch [15/50], Batch 33, Loss: 0.1303\n",
            "Epoch [15/50], Batch 34, Loss: 0.2649\n",
            "Epoch [15/50], Batch 35, Loss: 0.3257\n",
            "Epoch [15/50], Batch 36, Loss: 0.3049\n",
            "Epoch [15/50], Batch 37, Loss: 0.3695\n",
            "Epoch [15/50], Batch 38, Loss: 0.2182\n",
            "Epoch [15/50], Batch 39, Loss: 0.2031\n",
            "Epoch [15/50], Batch 40, Loss: 0.2240\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [16/50], Batch 1, Loss: 0.1694\n",
            "Epoch [16/50], Batch 2, Loss: 0.2022\n",
            "Epoch [16/50], Batch 3, Loss: 0.2748\n",
            "Epoch [16/50], Batch 4, Loss: 0.1872\n",
            "Epoch [16/50], Batch 5, Loss: 0.1713\n",
            "Epoch [16/50], Batch 6, Loss: 0.2909\n",
            "Epoch [16/50], Batch 7, Loss: 0.2111\n",
            "Epoch [16/50], Batch 8, Loss: 0.1389\n",
            "Epoch [16/50], Batch 9, Loss: 0.2082\n",
            "Epoch [16/50], Batch 10, Loss: 0.1682\n",
            "Epoch [16/50], Batch 11, Loss: 0.2948\n",
            "Epoch [16/50], Batch 12, Loss: 0.1969\n",
            "Epoch [16/50], Batch 13, Loss: 0.2286\n",
            "Epoch [16/50], Batch 14, Loss: 0.2719\n",
            "Epoch [16/50], Batch 15, Loss: 0.2006\n",
            "Epoch [16/50], Batch 16, Loss: 0.1626\n",
            "Epoch [16/50], Batch 17, Loss: 0.2381\n",
            "Epoch [16/50], Batch 18, Loss: 0.2474\n",
            "Epoch [16/50], Batch 19, Loss: 0.2612\n",
            "Epoch [16/50], Batch 20, Loss: 0.1621\n",
            "Epoch [16/50], Batch 21, Loss: 0.2685\n",
            "Epoch [16/50], Batch 22, Loss: 0.1000\n",
            "Epoch [16/50], Batch 23, Loss: 0.2091\n",
            "Epoch [16/50], Batch 24, Loss: 0.2313\n",
            "Epoch [16/50], Batch 25, Loss: 0.2095\n",
            "Epoch [16/50], Batch 26, Loss: 0.2517\n",
            "Epoch [16/50], Batch 27, Loss: 0.1353\n",
            "Epoch [16/50], Batch 28, Loss: 0.2797\n",
            "Epoch [16/50], Batch 29, Loss: 0.3080\n",
            "Epoch [16/50], Batch 30, Loss: 0.2099\n",
            "Epoch [16/50], Batch 31, Loss: 0.2604\n",
            "Epoch [16/50], Batch 32, Loss: 0.2031\n",
            "Epoch [16/50], Batch 33, Loss: 0.1606\n",
            "Epoch [16/50], Batch 34, Loss: 0.2599\n",
            "Epoch [16/50], Batch 35, Loss: 0.3152\n",
            "Epoch [16/50], Batch 36, Loss: 0.2800\n",
            "Epoch [16/50], Batch 37, Loss: 0.2424\n",
            "Epoch [16/50], Batch 38, Loss: 0.2244\n",
            "Epoch [16/50], Batch 39, Loss: 0.3147\n",
            "Epoch [16/50], Batch 40, Loss: 0.3084\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [17/50], Batch 1, Loss: 0.1392\n",
            "Epoch [17/50], Batch 2, Loss: 0.3185\n",
            "Epoch [17/50], Batch 3, Loss: 0.1895\n",
            "Epoch [17/50], Batch 4, Loss: 0.3423\n",
            "Epoch [17/50], Batch 5, Loss: 0.2903\n",
            "Epoch [17/50], Batch 6, Loss: 0.2063\n",
            "Epoch [17/50], Batch 7, Loss: 0.3012\n",
            "Epoch [17/50], Batch 8, Loss: 0.1794\n",
            "Epoch [17/50], Batch 9, Loss: 0.2194\n",
            "Epoch [17/50], Batch 10, Loss: 0.1669\n",
            "Epoch [17/50], Batch 11, Loss: 0.2573\n",
            "Epoch [17/50], Batch 12, Loss: 0.1526\n",
            "Epoch [17/50], Batch 13, Loss: 0.2565\n",
            "Epoch [17/50], Batch 14, Loss: 0.2198\n",
            "Epoch [17/50], Batch 15, Loss: 0.2165\n",
            "Epoch [17/50], Batch 16, Loss: 0.2678\n",
            "Epoch [17/50], Batch 17, Loss: 0.1589\n",
            "Epoch [17/50], Batch 18, Loss: 0.2943\n",
            "Epoch [17/50], Batch 19, Loss: 0.3126\n",
            "Epoch [17/50], Batch 20, Loss: 0.1967\n",
            "Epoch [17/50], Batch 21, Loss: 0.2598\n",
            "Epoch [17/50], Batch 22, Loss: 0.3740\n",
            "Epoch [17/50], Batch 23, Loss: 0.1631\n",
            "Epoch [17/50], Batch 24, Loss: 0.2449\n",
            "Epoch [17/50], Batch 25, Loss: 0.2251\n",
            "Epoch [17/50], Batch 26, Loss: 0.2651\n",
            "Epoch [17/50], Batch 27, Loss: 0.2580\n",
            "Epoch [17/50], Batch 28, Loss: 0.1782\n",
            "Epoch [17/50], Batch 29, Loss: 0.2614\n",
            "Epoch [17/50], Batch 30, Loss: 0.2825\n",
            "Epoch [17/50], Batch 31, Loss: 0.2561\n",
            "Epoch [17/50], Batch 32, Loss: 0.2517\n",
            "Epoch [17/50], Batch 33, Loss: 0.2093\n",
            "Epoch [17/50], Batch 34, Loss: 0.2508\n",
            "Epoch [17/50], Batch 35, Loss: 0.2328\n",
            "Epoch [17/50], Batch 36, Loss: 0.1692\n",
            "Epoch [17/50], Batch 37, Loss: 0.1942\n",
            "Epoch [17/50], Batch 38, Loss: 0.2760\n",
            "Epoch [17/50], Batch 39, Loss: 0.2035\n",
            "Epoch [17/50], Batch 40, Loss: 0.2078\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [18/50], Batch 1, Loss: 0.2276\n",
            "Epoch [18/50], Batch 2, Loss: 0.1246\n",
            "Epoch [18/50], Batch 3, Loss: 0.2252\n",
            "Epoch [18/50], Batch 4, Loss: 0.2295\n",
            "Epoch [18/50], Batch 5, Loss: 0.2042\n",
            "Epoch [18/50], Batch 6, Loss: 0.1740\n",
            "Epoch [18/50], Batch 7, Loss: 0.1149\n",
            "Epoch [18/50], Batch 8, Loss: 0.1834\n",
            "Epoch [18/50], Batch 9, Loss: 0.2337\n",
            "Epoch [18/50], Batch 10, Loss: 0.2070\n",
            "Epoch [18/50], Batch 11, Loss: 0.2534\n",
            "Epoch [18/50], Batch 12, Loss: 0.2419\n",
            "Epoch [18/50], Batch 13, Loss: 0.1997\n",
            "Epoch [18/50], Batch 14, Loss: 0.2514\n",
            "Epoch [18/50], Batch 15, Loss: 0.2873\n",
            "Epoch [18/50], Batch 16, Loss: 0.2096\n",
            "Epoch [18/50], Batch 17, Loss: 0.2423\n",
            "Epoch [18/50], Batch 18, Loss: 0.2600\n",
            "Epoch [18/50], Batch 19, Loss: 0.2433\n",
            "Epoch [18/50], Batch 20, Loss: 0.2204\n",
            "Epoch [18/50], Batch 21, Loss: 0.1564\n",
            "Epoch [18/50], Batch 22, Loss: 0.2332\n",
            "Epoch [18/50], Batch 23, Loss: 0.2283\n",
            "Epoch [18/50], Batch 24, Loss: 0.3419\n",
            "Epoch [18/50], Batch 25, Loss: 0.1320\n",
            "Epoch [18/50], Batch 26, Loss: 0.1644\n",
            "Epoch [18/50], Batch 27, Loss: 0.2108\n",
            "Epoch [18/50], Batch 28, Loss: 0.3015\n",
            "Epoch [18/50], Batch 29, Loss: 0.2274\n",
            "Epoch [18/50], Batch 30, Loss: 0.2043\n",
            "Epoch [18/50], Batch 31, Loss: 0.2271\n",
            "Epoch [18/50], Batch 32, Loss: 0.2684\n",
            "Epoch [18/50], Batch 33, Loss: 0.2260\n",
            "Epoch [18/50], Batch 34, Loss: 0.1671\n",
            "Epoch [18/50], Batch 35, Loss: 0.2367\n",
            "Epoch [18/50], Batch 36, Loss: 0.1715\n",
            "Epoch [18/50], Batch 37, Loss: 0.1940\n",
            "Epoch [18/50], Batch 38, Loss: 0.3221\n",
            "Epoch [18/50], Batch 39, Loss: 0.2614\n",
            "Epoch [18/50], Batch 40, Loss: 0.2647\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [19/50], Batch 1, Loss: 0.1826\n",
            "Epoch [19/50], Batch 2, Loss: 0.2693\n",
            "Epoch [19/50], Batch 3, Loss: 0.1773\n",
            "Epoch [19/50], Batch 4, Loss: 0.2551\n",
            "Epoch [19/50], Batch 5, Loss: 0.1999\n",
            "Epoch [19/50], Batch 6, Loss: 0.2021\n",
            "Epoch [19/50], Batch 7, Loss: 0.1531\n",
            "Epoch [19/50], Batch 8, Loss: 0.3140\n",
            "Epoch [19/50], Batch 9, Loss: 0.2175\n",
            "Epoch [19/50], Batch 10, Loss: 0.1639\n",
            "Epoch [19/50], Batch 11, Loss: 0.2493\n",
            "Epoch [19/50], Batch 12, Loss: 0.1621\n",
            "Epoch [19/50], Batch 13, Loss: 0.2794\n",
            "Epoch [19/50], Batch 14, Loss: 0.1904\n",
            "Epoch [19/50], Batch 15, Loss: 0.1918\n",
            "Epoch [19/50], Batch 16, Loss: 0.3961\n",
            "Epoch [19/50], Batch 17, Loss: 0.1989\n",
            "Epoch [19/50], Batch 18, Loss: 0.2553\n",
            "Epoch [19/50], Batch 19, Loss: 0.3009\n",
            "Epoch [19/50], Batch 20, Loss: 0.2080\n",
            "Epoch [19/50], Batch 21, Loss: 0.3156\n",
            "Epoch [19/50], Batch 22, Loss: 0.1780\n",
            "Epoch [19/50], Batch 23, Loss: 0.2343\n",
            "Epoch [19/50], Batch 24, Loss: 0.2809\n",
            "Epoch [19/50], Batch 25, Loss: 0.3036\n",
            "Epoch [19/50], Batch 26, Loss: 0.1913\n",
            "Epoch [19/50], Batch 27, Loss: 0.4005\n",
            "Epoch [19/50], Batch 28, Loss: 0.2321\n",
            "Epoch [19/50], Batch 29, Loss: 0.2286\n",
            "Epoch [19/50], Batch 30, Loss: 0.1765\n",
            "Epoch [19/50], Batch 31, Loss: 0.2565\n",
            "Epoch [19/50], Batch 32, Loss: 0.2060\n",
            "Epoch [19/50], Batch 33, Loss: 0.1920\n",
            "Epoch [19/50], Batch 34, Loss: 0.1537\n",
            "Epoch [19/50], Batch 35, Loss: 0.2326\n",
            "Epoch [19/50], Batch 36, Loss: 0.2397\n",
            "Epoch [19/50], Batch 37, Loss: 0.1672\n",
            "Epoch [19/50], Batch 38, Loss: 0.2342\n",
            "Epoch [19/50], Batch 39, Loss: 0.2071\n",
            "Epoch [19/50], Batch 40, Loss: 0.1587\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [20/50], Batch 1, Loss: 0.2350\n",
            "Epoch [20/50], Batch 2, Loss: 0.1670\n",
            "Epoch [20/50], Batch 3, Loss: 0.2503\n",
            "Epoch [20/50], Batch 4, Loss: 0.2314\n",
            "Epoch [20/50], Batch 5, Loss: 0.2813\n",
            "Epoch [20/50], Batch 6, Loss: 0.1941\n",
            "Epoch [20/50], Batch 7, Loss: 0.2854\n",
            "Epoch [20/50], Batch 8, Loss: 0.1411\n",
            "Epoch [20/50], Batch 9, Loss: 0.2020\n",
            "Epoch [20/50], Batch 10, Loss: 0.1906\n",
            "Epoch [20/50], Batch 11, Loss: 0.2195\n",
            "Epoch [20/50], Batch 12, Loss: 0.2088\n",
            "Epoch [20/50], Batch 13, Loss: 0.2679\n",
            "Epoch [20/50], Batch 14, Loss: 0.1934\n",
            "Epoch [20/50], Batch 15, Loss: 0.1387\n",
            "Epoch [20/50], Batch 16, Loss: 0.1666\n",
            "Epoch [20/50], Batch 17, Loss: 0.1892\n",
            "Epoch [20/50], Batch 18, Loss: 0.2446\n",
            "Epoch [20/50], Batch 19, Loss: 0.2298\n",
            "Epoch [20/50], Batch 20, Loss: 0.1076\n",
            "Epoch [20/50], Batch 21, Loss: 0.2707\n",
            "Epoch [20/50], Batch 22, Loss: 0.1883\n",
            "Epoch [20/50], Batch 23, Loss: 0.3439\n",
            "Epoch [20/50], Batch 24, Loss: 0.1429\n",
            "Epoch [20/50], Batch 25, Loss: 0.1593\n",
            "Epoch [20/50], Batch 26, Loss: 0.2617\n",
            "Epoch [20/50], Batch 27, Loss: 0.2182\n",
            "Epoch [20/50], Batch 28, Loss: 0.1521\n",
            "Epoch [20/50], Batch 29, Loss: 0.3501\n",
            "Epoch [20/50], Batch 30, Loss: 0.2331\n",
            "Epoch [20/50], Batch 31, Loss: 0.2025\n",
            "Epoch [20/50], Batch 32, Loss: 0.1611\n",
            "Epoch [20/50], Batch 33, Loss: 0.3122\n",
            "Epoch [20/50], Batch 34, Loss: 0.2119\n",
            "Epoch [20/50], Batch 35, Loss: 0.2286\n",
            "Epoch [20/50], Batch 36, Loss: 0.1870\n",
            "Epoch [20/50], Batch 37, Loss: 0.3786\n",
            "Epoch [20/50], Batch 38, Loss: 0.2215\n",
            "Epoch [20/50], Batch 39, Loss: 0.1777\n",
            "Epoch [20/50], Batch 40, Loss: 0.3212\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [21/50], Batch 1, Loss: 0.1745\n",
            "Epoch [21/50], Batch 2, Loss: 0.2084\n",
            "Epoch [21/50], Batch 3, Loss: 0.2860\n",
            "Epoch [21/50], Batch 4, Loss: 0.2343\n",
            "Epoch [21/50], Batch 5, Loss: 0.2052\n",
            "Epoch [21/50], Batch 6, Loss: 0.2826\n",
            "Epoch [21/50], Batch 7, Loss: 0.2523\n",
            "Epoch [21/50], Batch 8, Loss: 0.2131\n",
            "Epoch [21/50], Batch 9, Loss: 0.1859\n",
            "Epoch [21/50], Batch 10, Loss: 0.2448\n",
            "Epoch [21/50], Batch 11, Loss: 0.2375\n",
            "Epoch [21/50], Batch 12, Loss: 0.3395\n",
            "Epoch [21/50], Batch 13, Loss: 0.2328\n",
            "Epoch [21/50], Batch 14, Loss: 0.2056\n",
            "Epoch [21/50], Batch 15, Loss: 0.2571\n",
            "Epoch [21/50], Batch 16, Loss: 0.2773\n",
            "Epoch [21/50], Batch 17, Loss: 0.1892\n",
            "Epoch [21/50], Batch 18, Loss: 0.2500\n",
            "Epoch [21/50], Batch 19, Loss: 0.2489\n",
            "Epoch [21/50], Batch 20, Loss: 0.3029\n",
            "Epoch [21/50], Batch 21, Loss: 0.2134\n",
            "Epoch [21/50], Batch 22, Loss: 0.1644\n",
            "Epoch [21/50], Batch 23, Loss: 0.2378\n",
            "Epoch [21/50], Batch 24, Loss: 0.2059\n",
            "Epoch [21/50], Batch 25, Loss: 0.1673\n",
            "Epoch [21/50], Batch 26, Loss: 0.2179\n",
            "Epoch [21/50], Batch 27, Loss: 0.1716\n",
            "Epoch [21/50], Batch 28, Loss: 0.1183\n",
            "Epoch [21/50], Batch 29, Loss: 0.2032\n",
            "Epoch [21/50], Batch 30, Loss: 0.2167\n",
            "Epoch [21/50], Batch 31, Loss: 0.2752\n",
            "Epoch [21/50], Batch 32, Loss: 0.1679\n",
            "Epoch [21/50], Batch 33, Loss: 0.2980\n",
            "Epoch [21/50], Batch 34, Loss: 0.2228\n",
            "Epoch [21/50], Batch 35, Loss: 0.3637\n",
            "Epoch [21/50], Batch 36, Loss: 0.2252\n",
            "Epoch [21/50], Batch 37, Loss: 0.2570\n",
            "Epoch [21/50], Batch 38, Loss: 0.2342\n",
            "Epoch [21/50], Batch 39, Loss: 0.3267\n",
            "Epoch [21/50], Batch 40, Loss: 0.1972\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [22/50], Batch 1, Loss: 0.2655\n",
            "Epoch [22/50], Batch 2, Loss: 0.1808\n",
            "Epoch [22/50], Batch 3, Loss: 0.2409\n",
            "Epoch [22/50], Batch 4, Loss: 0.1470\n",
            "Epoch [22/50], Batch 5, Loss: 0.2300\n",
            "Epoch [22/50], Batch 6, Loss: 0.1943\n",
            "Epoch [22/50], Batch 7, Loss: 0.2673\n",
            "Epoch [22/50], Batch 8, Loss: 0.2854\n",
            "Epoch [22/50], Batch 9, Loss: 0.2471\n",
            "Epoch [22/50], Batch 10, Loss: 0.2573\n",
            "Epoch [22/50], Batch 11, Loss: 0.2467\n",
            "Epoch [22/50], Batch 12, Loss: 0.3333\n",
            "Epoch [22/50], Batch 13, Loss: 0.2489\n",
            "Epoch [22/50], Batch 14, Loss: 0.2952\n",
            "Epoch [22/50], Batch 15, Loss: 0.2537\n",
            "Epoch [22/50], Batch 16, Loss: 0.2288\n",
            "Epoch [22/50], Batch 17, Loss: 0.3307\n",
            "Epoch [22/50], Batch 18, Loss: 0.2860\n",
            "Epoch [22/50], Batch 19, Loss: 0.2587\n",
            "Epoch [22/50], Batch 20, Loss: 0.1666\n",
            "Epoch [22/50], Batch 21, Loss: 0.2168\n",
            "Epoch [22/50], Batch 22, Loss: 0.2887\n",
            "Epoch [22/50], Batch 23, Loss: 0.2446\n",
            "Epoch [22/50], Batch 24, Loss: 0.1731\n",
            "Epoch [22/50], Batch 25, Loss: 0.3026\n",
            "Epoch [22/50], Batch 26, Loss: 0.2554\n",
            "Epoch [22/50], Batch 27, Loss: 0.2237\n",
            "Epoch [22/50], Batch 28, Loss: 0.1725\n",
            "Epoch [22/50], Batch 29, Loss: 0.2013\n",
            "Epoch [22/50], Batch 30, Loss: 0.3135\n",
            "Epoch [22/50], Batch 31, Loss: 0.1650\n",
            "Epoch [22/50], Batch 32, Loss: 0.3255\n",
            "Epoch [22/50], Batch 33, Loss: 0.2302\n",
            "Epoch [22/50], Batch 34, Loss: 0.4013\n",
            "Epoch [22/50], Batch 35, Loss: 0.1766\n",
            "Epoch [22/50], Batch 36, Loss: 0.2532\n",
            "Epoch [22/50], Batch 37, Loss: 0.1932\n",
            "Epoch [22/50], Batch 38, Loss: 0.2537\n",
            "Epoch [22/50], Batch 39, Loss: 0.3531\n",
            "Epoch [22/50], Batch 40, Loss: 0.3158\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [23/50], Batch 1, Loss: 0.2687\n",
            "Epoch [23/50], Batch 2, Loss: 0.2309\n",
            "Epoch [23/50], Batch 3, Loss: 0.1770\n",
            "Epoch [23/50], Batch 4, Loss: 0.1848\n",
            "Epoch [23/50], Batch 5, Loss: 0.2163\n",
            "Epoch [23/50], Batch 6, Loss: 0.1807\n",
            "Epoch [23/50], Batch 7, Loss: 0.1387\n",
            "Epoch [23/50], Batch 8, Loss: 0.2498\n",
            "Epoch [23/50], Batch 9, Loss: 0.1895\n",
            "Epoch [23/50], Batch 10, Loss: 0.3019\n",
            "Epoch [23/50], Batch 11, Loss: 0.3244\n",
            "Epoch [23/50], Batch 12, Loss: 0.1813\n",
            "Epoch [23/50], Batch 13, Loss: 0.1964\n",
            "Epoch [23/50], Batch 14, Loss: 0.2752\n",
            "Epoch [23/50], Batch 15, Loss: 0.1883\n",
            "Epoch [23/50], Batch 16, Loss: 0.2649\n",
            "Epoch [23/50], Batch 17, Loss: 0.1755\n",
            "Epoch [23/50], Batch 18, Loss: 0.2739\n",
            "Epoch [23/50], Batch 19, Loss: 0.1957\n",
            "Epoch [23/50], Batch 20, Loss: 0.2159\n",
            "Epoch [23/50], Batch 21, Loss: 0.2399\n",
            "Epoch [23/50], Batch 22, Loss: 0.1836\n",
            "Epoch [23/50], Batch 23, Loss: 0.2102\n",
            "Epoch [23/50], Batch 24, Loss: 0.2244\n",
            "Epoch [23/50], Batch 25, Loss: 0.1781\n",
            "Epoch [23/50], Batch 26, Loss: 0.2632\n",
            "Epoch [23/50], Batch 27, Loss: 0.2429\n",
            "Epoch [23/50], Batch 28, Loss: 0.2266\n",
            "Epoch [23/50], Batch 29, Loss: 0.1890\n",
            "Epoch [23/50], Batch 30, Loss: 0.2279\n",
            "Epoch [23/50], Batch 31, Loss: 0.1921\n",
            "Epoch [23/50], Batch 32, Loss: 0.2812\n",
            "Epoch [23/50], Batch 33, Loss: 0.3152\n",
            "Epoch [23/50], Batch 34, Loss: 0.2504\n",
            "Epoch [23/50], Batch 35, Loss: 0.2027\n",
            "Epoch [23/50], Batch 36, Loss: 0.2863\n",
            "Epoch [23/50], Batch 37, Loss: 0.2429\n",
            "Epoch [23/50], Batch 38, Loss: 0.2845\n",
            "Epoch [23/50], Batch 39, Loss: 0.1918\n",
            "Epoch [23/50], Batch 40, Loss: 0.2747\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [24/50], Batch 1, Loss: 0.2309\n",
            "Epoch [24/50], Batch 2, Loss: 0.2839\n",
            "Epoch [24/50], Batch 3, Loss: 0.1690\n",
            "Epoch [24/50], Batch 4, Loss: 0.2172\n",
            "Epoch [24/50], Batch 5, Loss: 0.1798\n",
            "Epoch [24/50], Batch 6, Loss: 0.1709\n",
            "Epoch [24/50], Batch 7, Loss: 0.1434\n",
            "Epoch [24/50], Batch 8, Loss: 0.2582\n",
            "Epoch [24/50], Batch 9, Loss: 0.1302\n",
            "Epoch [24/50], Batch 10, Loss: 0.1540\n",
            "Epoch [24/50], Batch 11, Loss: 0.2520\n",
            "Epoch [24/50], Batch 12, Loss: 0.1687\n",
            "Epoch [24/50], Batch 13, Loss: 0.1699\n",
            "Epoch [24/50], Batch 14, Loss: 0.1537\n",
            "Epoch [24/50], Batch 15, Loss: 0.1151\n",
            "Epoch [24/50], Batch 16, Loss: 0.2257\n",
            "Epoch [24/50], Batch 17, Loss: 0.2204\n",
            "Epoch [24/50], Batch 18, Loss: 0.1505\n",
            "Epoch [24/50], Batch 19, Loss: 0.2291\n",
            "Epoch [24/50], Batch 20, Loss: 0.2501\n",
            "Epoch [24/50], Batch 21, Loss: 0.2594\n",
            "Epoch [24/50], Batch 22, Loss: 0.2353\n",
            "Epoch [24/50], Batch 23, Loss: 0.2164\n",
            "Epoch [24/50], Batch 24, Loss: 0.4500\n",
            "Epoch [24/50], Batch 25, Loss: 0.1944\n",
            "Epoch [24/50], Batch 26, Loss: 0.1547\n",
            "Epoch [24/50], Batch 27, Loss: 0.2561\n",
            "Epoch [24/50], Batch 28, Loss: 0.2929\n",
            "Epoch [24/50], Batch 29, Loss: 0.3127\n",
            "Epoch [24/50], Batch 30, Loss: 0.1941\n",
            "Epoch [24/50], Batch 31, Loss: 0.2669\n",
            "Epoch [24/50], Batch 32, Loss: 0.2553\n",
            "Epoch [24/50], Batch 33, Loss: 0.2377\n",
            "Epoch [24/50], Batch 34, Loss: 0.2795\n",
            "Epoch [24/50], Batch 35, Loss: 0.2772\n",
            "Epoch [24/50], Batch 36, Loss: 0.3323\n",
            "Epoch [24/50], Batch 37, Loss: 0.2113\n",
            "Epoch [24/50], Batch 38, Loss: 0.2557\n",
            "Epoch [24/50], Batch 39, Loss: 0.2196\n",
            "Epoch [24/50], Batch 40, Loss: 0.2457\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [25/50], Batch 1, Loss: 0.2233\n",
            "Epoch [25/50], Batch 2, Loss: 0.3159\n",
            "Epoch [25/50], Batch 3, Loss: 0.2248\n",
            "Epoch [25/50], Batch 4, Loss: 0.2214\n",
            "Epoch [25/50], Batch 5, Loss: 0.3214\n",
            "Epoch [25/50], Batch 6, Loss: 0.3246\n",
            "Epoch [25/50], Batch 7, Loss: 0.2744\n",
            "Epoch [25/50], Batch 8, Loss: 0.1903\n",
            "Epoch [25/50], Batch 9, Loss: 0.2500\n",
            "Epoch [25/50], Batch 10, Loss: 0.2051\n",
            "Epoch [25/50], Batch 11, Loss: 0.2764\n",
            "Epoch [25/50], Batch 12, Loss: 0.4164\n",
            "Epoch [25/50], Batch 13, Loss: 0.2270\n",
            "Epoch [25/50], Batch 14, Loss: 0.1941\n",
            "Epoch [25/50], Batch 15, Loss: 0.1864\n",
            "Epoch [25/50], Batch 16, Loss: 0.4105\n",
            "Epoch [25/50], Batch 17, Loss: 0.3297\n",
            "Epoch [25/50], Batch 18, Loss: 0.2393\n",
            "Epoch [25/50], Batch 19, Loss: 0.3185\n",
            "Epoch [25/50], Batch 20, Loss: 0.1865\n",
            "Epoch [25/50], Batch 21, Loss: 0.1991\n",
            "Epoch [25/50], Batch 22, Loss: 0.2079\n",
            "Epoch [25/50], Batch 23, Loss: 0.1846\n",
            "Epoch [25/50], Batch 24, Loss: 0.2931\n",
            "Epoch [25/50], Batch 25, Loss: 0.1899\n",
            "Epoch [25/50], Batch 26, Loss: 0.2162\n",
            "Epoch [25/50], Batch 27, Loss: 0.2313\n",
            "Epoch [25/50], Batch 28, Loss: 0.1259\n",
            "Epoch [25/50], Batch 29, Loss: 0.1385\n",
            "Epoch [25/50], Batch 30, Loss: 0.2314\n",
            "Epoch [25/50], Batch 31, Loss: 0.2521\n",
            "Epoch [25/50], Batch 32, Loss: 0.1272\n",
            "Epoch [25/50], Batch 33, Loss: 0.2399\n",
            "Epoch [25/50], Batch 34, Loss: 0.2462\n",
            "Epoch [25/50], Batch 35, Loss: 0.2324\n",
            "Epoch [25/50], Batch 36, Loss: 0.1629\n",
            "Epoch [25/50], Batch 37, Loss: 0.1814\n",
            "Epoch [25/50], Batch 38, Loss: 0.3352\n",
            "Epoch [25/50], Batch 39, Loss: 0.2255\n",
            "Epoch [25/50], Batch 40, Loss: 0.1751\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [26/50], Batch 1, Loss: 0.1529\n",
            "Epoch [26/50], Batch 2, Loss: 0.2033\n",
            "Epoch [26/50], Batch 3, Loss: 0.1543\n",
            "Epoch [26/50], Batch 4, Loss: 0.1401\n",
            "Epoch [26/50], Batch 5, Loss: 0.2951\n",
            "Epoch [26/50], Batch 6, Loss: 0.1433\n",
            "Epoch [26/50], Batch 7, Loss: 0.2919\n",
            "Epoch [26/50], Batch 8, Loss: 0.3195\n",
            "Epoch [26/50], Batch 9, Loss: 0.3657\n",
            "Epoch [26/50], Batch 10, Loss: 0.1945\n",
            "Epoch [26/50], Batch 11, Loss: 0.1888\n",
            "Epoch [26/50], Batch 12, Loss: 0.2437\n",
            "Epoch [26/50], Batch 13, Loss: 0.2686\n",
            "Epoch [26/50], Batch 14, Loss: 0.1678\n",
            "Epoch [26/50], Batch 15, Loss: 0.2267\n",
            "Epoch [26/50], Batch 16, Loss: 0.2805\n",
            "Epoch [26/50], Batch 17, Loss: 0.1516\n",
            "Epoch [26/50], Batch 18, Loss: 0.2349\n",
            "Epoch [26/50], Batch 19, Loss: 0.1339\n",
            "Epoch [26/50], Batch 20, Loss: 0.2553\n",
            "Epoch [26/50], Batch 21, Loss: 0.3377\n",
            "Epoch [26/50], Batch 22, Loss: 0.1810\n",
            "Epoch [26/50], Batch 23, Loss: 0.1606\n",
            "Epoch [26/50], Batch 24, Loss: 0.1322\n",
            "Epoch [26/50], Batch 25, Loss: 0.2369\n",
            "Epoch [26/50], Batch 26, Loss: 0.2596\n",
            "Epoch [26/50], Batch 27, Loss: 0.2884\n",
            "Epoch [26/50], Batch 28, Loss: 0.1731\n",
            "Epoch [26/50], Batch 29, Loss: 0.2038\n",
            "Epoch [26/50], Batch 30, Loss: 0.2038\n",
            "Epoch [26/50], Batch 31, Loss: 0.1545\n",
            "Epoch [26/50], Batch 32, Loss: 0.3364\n",
            "Epoch [26/50], Batch 33, Loss: 0.1870\n",
            "Epoch [26/50], Batch 34, Loss: 0.2220\n",
            "Epoch [26/50], Batch 35, Loss: 0.2460\n",
            "Epoch [26/50], Batch 36, Loss: 0.2084\n",
            "Epoch [26/50], Batch 37, Loss: 0.2159\n",
            "Epoch [26/50], Batch 38, Loss: 0.1569\n",
            "Epoch [26/50], Batch 39, Loss: 0.2759\n",
            "Epoch [26/50], Batch 40, Loss: 0.2457\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [27/50], Batch 1, Loss: 0.1453\n",
            "Epoch [27/50], Batch 2, Loss: 0.1161\n",
            "Epoch [27/50], Batch 3, Loss: 0.1555\n",
            "Epoch [27/50], Batch 4, Loss: 0.1266\n",
            "Epoch [27/50], Batch 5, Loss: 0.2024\n",
            "Epoch [27/50], Batch 6, Loss: 0.2109\n",
            "Epoch [27/50], Batch 7, Loss: 0.1280\n",
            "Epoch [27/50], Batch 8, Loss: 0.1169\n",
            "Epoch [27/50], Batch 9, Loss: 0.0934\n",
            "Epoch [27/50], Batch 10, Loss: 0.2178\n",
            "Epoch [27/50], Batch 11, Loss: 0.1593\n",
            "Epoch [27/50], Batch 12, Loss: 0.1191\n",
            "Epoch [27/50], Batch 13, Loss: 0.1733\n",
            "Epoch [27/50], Batch 14, Loss: 0.2165\n",
            "Epoch [27/50], Batch 15, Loss: 0.2862\n",
            "Epoch [27/50], Batch 16, Loss: 0.2019\n",
            "Epoch [27/50], Batch 17, Loss: 0.2020\n",
            "Epoch [27/50], Batch 18, Loss: 0.2529\n",
            "Epoch [27/50], Batch 19, Loss: 0.1045\n",
            "Epoch [27/50], Batch 20, Loss: 0.1184\n",
            "Epoch [27/50], Batch 21, Loss: 0.1634\n",
            "Epoch [27/50], Batch 22, Loss: 0.2101\n",
            "Epoch [27/50], Batch 23, Loss: 0.1622\n",
            "Epoch [27/50], Batch 24, Loss: 0.1112\n",
            "Epoch [27/50], Batch 25, Loss: 0.1855\n",
            "Epoch [27/50], Batch 26, Loss: 0.1930\n",
            "Epoch [27/50], Batch 27, Loss: 0.1621\n",
            "Epoch [27/50], Batch 28, Loss: 0.1324\n",
            "Epoch [27/50], Batch 29, Loss: 0.1293\n",
            "Epoch [27/50], Batch 30, Loss: 0.2197\n",
            "Epoch [27/50], Batch 31, Loss: 0.1532\n",
            "Epoch [27/50], Batch 32, Loss: 0.1601\n",
            "Epoch [27/50], Batch 33, Loss: 0.2072\n",
            "Epoch [27/50], Batch 34, Loss: 0.1515\n",
            "Epoch [27/50], Batch 35, Loss: 0.1790\n",
            "Epoch [27/50], Batch 36, Loss: 0.1262\n",
            "Epoch [27/50], Batch 37, Loss: 0.1851\n",
            "Epoch [27/50], Batch 38, Loss: 0.2335\n",
            "Epoch [27/50], Batch 39, Loss: 0.1824\n",
            "Epoch [27/50], Batch 40, Loss: 0.2465\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [28/50], Batch 1, Loss: 0.1841\n",
            "Epoch [28/50], Batch 2, Loss: 0.1626\n",
            "Epoch [28/50], Batch 3, Loss: 0.1460\n",
            "Epoch [28/50], Batch 4, Loss: 0.1603\n",
            "Epoch [28/50], Batch 5, Loss: 0.1213\n",
            "Epoch [28/50], Batch 6, Loss: 0.1908\n",
            "Epoch [28/50], Batch 7, Loss: 0.1437\n",
            "Epoch [28/50], Batch 8, Loss: 0.2072\n",
            "Epoch [28/50], Batch 9, Loss: 0.1705\n",
            "Epoch [28/50], Batch 10, Loss: 0.1418\n",
            "Epoch [28/50], Batch 11, Loss: 0.2247\n",
            "Epoch [28/50], Batch 12, Loss: 0.1131\n",
            "Epoch [28/50], Batch 13, Loss: 0.1784\n",
            "Epoch [28/50], Batch 14, Loss: 0.1808\n",
            "Epoch [28/50], Batch 15, Loss: 0.1568\n",
            "Epoch [28/50], Batch 16, Loss: 0.3152\n",
            "Epoch [28/50], Batch 17, Loss: 0.1516\n",
            "Epoch [28/50], Batch 18, Loss: 0.1441\n",
            "Epoch [28/50], Batch 19, Loss: 0.2975\n",
            "Epoch [28/50], Batch 20, Loss: 0.0739\n",
            "Epoch [28/50], Batch 21, Loss: 0.1333\n",
            "Epoch [28/50], Batch 22, Loss: 0.2888\n",
            "Epoch [28/50], Batch 23, Loss: 0.2157\n",
            "Epoch [28/50], Batch 24, Loss: 0.2528\n",
            "Epoch [28/50], Batch 25, Loss: 0.1102\n",
            "Epoch [28/50], Batch 26, Loss: 0.1750\n",
            "Epoch [28/50], Batch 27, Loss: 0.2010\n",
            "Epoch [28/50], Batch 28, Loss: 0.1999\n",
            "Epoch [28/50], Batch 29, Loss: 0.1312\n",
            "Epoch [28/50], Batch 30, Loss: 0.1559\n",
            "Epoch [28/50], Batch 31, Loss: 0.2442\n",
            "Epoch [28/50], Batch 32, Loss: 0.1793\n",
            "Epoch [28/50], Batch 33, Loss: 0.2048\n",
            "Epoch [28/50], Batch 34, Loss: 0.1155\n",
            "Epoch [28/50], Batch 35, Loss: 0.1755\n",
            "Epoch [28/50], Batch 36, Loss: 0.1650\n",
            "Epoch [28/50], Batch 37, Loss: 0.1504\n",
            "Epoch [28/50], Batch 38, Loss: 0.2046\n",
            "Epoch [28/50], Batch 39, Loss: 0.1651\n",
            "Epoch [28/50], Batch 40, Loss: 0.0871\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [29/50], Batch 1, Loss: 0.2158\n",
            "Epoch [29/50], Batch 2, Loss: 0.1057\n",
            "Epoch [29/50], Batch 3, Loss: 0.1890\n",
            "Epoch [29/50], Batch 4, Loss: 0.1839\n",
            "Epoch [29/50], Batch 5, Loss: 0.1914\n",
            "Epoch [29/50], Batch 6, Loss: 0.1530\n",
            "Epoch [29/50], Batch 7, Loss: 0.0955\n",
            "Epoch [29/50], Batch 8, Loss: 0.0911\n",
            "Epoch [29/50], Batch 9, Loss: 0.2227\n",
            "Epoch [29/50], Batch 10, Loss: 0.2072\n",
            "Epoch [29/50], Batch 11, Loss: 0.0955\n",
            "Epoch [29/50], Batch 12, Loss: 0.1336\n",
            "Epoch [29/50], Batch 13, Loss: 0.1138\n",
            "Epoch [29/50], Batch 14, Loss: 0.1574\n",
            "Epoch [29/50], Batch 15, Loss: 0.1676\n",
            "Epoch [29/50], Batch 16, Loss: 0.1349\n",
            "Epoch [29/50], Batch 17, Loss: 0.1030\n",
            "Epoch [29/50], Batch 18, Loss: 0.0958\n",
            "Epoch [29/50], Batch 19, Loss: 0.1117\n",
            "Epoch [29/50], Batch 20, Loss: 0.1643\n",
            "Epoch [29/50], Batch 21, Loss: 0.1337\n",
            "Epoch [29/50], Batch 22, Loss: 0.1866\n",
            "Epoch [29/50], Batch 23, Loss: 0.1670\n",
            "Epoch [29/50], Batch 24, Loss: 0.1520\n",
            "Epoch [29/50], Batch 25, Loss: 0.2133\n",
            "Epoch [29/50], Batch 26, Loss: 0.1335\n",
            "Epoch [29/50], Batch 27, Loss: 0.0958\n",
            "Epoch [29/50], Batch 28, Loss: 0.1980\n",
            "Epoch [29/50], Batch 29, Loss: 0.1981\n",
            "Epoch [29/50], Batch 30, Loss: 0.2247\n",
            "Epoch [29/50], Batch 31, Loss: 0.1514\n",
            "Epoch [29/50], Batch 32, Loss: 0.2847\n",
            "Epoch [29/50], Batch 33, Loss: 0.2125\n",
            "Epoch [29/50], Batch 34, Loss: 0.1413\n",
            "Epoch [29/50], Batch 35, Loss: 0.1824\n",
            "Epoch [29/50], Batch 36, Loss: 0.2706\n",
            "Epoch [29/50], Batch 37, Loss: 0.2026\n",
            "Epoch [29/50], Batch 38, Loss: 0.1942\n",
            "Epoch [29/50], Batch 39, Loss: 0.1995\n",
            "Epoch [29/50], Batch 40, Loss: 0.2431\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [30/50], Batch 1, Loss: 0.2259\n",
            "Epoch [30/50], Batch 2, Loss: 0.2026\n",
            "Epoch [30/50], Batch 3, Loss: 0.2043\n",
            "Epoch [30/50], Batch 4, Loss: 0.1921\n",
            "Epoch [30/50], Batch 5, Loss: 0.0938\n",
            "Epoch [30/50], Batch 6, Loss: 0.1587\n",
            "Epoch [30/50], Batch 7, Loss: 0.1323\n",
            "Epoch [30/50], Batch 8, Loss: 0.2106\n",
            "Epoch [30/50], Batch 9, Loss: 0.1940\n",
            "Epoch [30/50], Batch 10, Loss: 0.1228\n",
            "Epoch [30/50], Batch 11, Loss: 0.1660\n",
            "Epoch [30/50], Batch 12, Loss: 0.1771\n",
            "Epoch [30/50], Batch 13, Loss: 0.1879\n",
            "Epoch [30/50], Batch 14, Loss: 0.1158\n",
            "Epoch [30/50], Batch 15, Loss: 0.2441\n",
            "Epoch [30/50], Batch 16, Loss: 0.3176\n",
            "Epoch [30/50], Batch 17, Loss: 0.1674\n",
            "Epoch [30/50], Batch 18, Loss: 0.1512\n",
            "Epoch [30/50], Batch 19, Loss: 0.1867\n",
            "Epoch [30/50], Batch 20, Loss: 0.2246\n",
            "Epoch [30/50], Batch 21, Loss: 0.1762\n",
            "Epoch [30/50], Batch 22, Loss: 0.2207\n",
            "Epoch [30/50], Batch 23, Loss: 0.2414\n",
            "Epoch [30/50], Batch 24, Loss: 0.1615\n",
            "Epoch [30/50], Batch 25, Loss: 0.2900\n",
            "Epoch [30/50], Batch 26, Loss: 0.1576\n",
            "Epoch [30/50], Batch 27, Loss: 0.3822\n",
            "Epoch [30/50], Batch 28, Loss: 0.2122\n",
            "Epoch [30/50], Batch 29, Loss: 0.1608\n",
            "Epoch [30/50], Batch 30, Loss: 0.1513\n",
            "Epoch [30/50], Batch 31, Loss: 0.1072\n",
            "Epoch [30/50], Batch 32, Loss: 0.1201\n",
            "Epoch [30/50], Batch 33, Loss: 0.1851\n",
            "Epoch [30/50], Batch 34, Loss: 0.2035\n",
            "Epoch [30/50], Batch 35, Loss: 0.2311\n",
            "Epoch [30/50], Batch 36, Loss: 0.1767\n",
            "Epoch [30/50], Batch 37, Loss: 0.1636\n",
            "Epoch [30/50], Batch 38, Loss: 0.1807\n",
            "Epoch [30/50], Batch 39, Loss: 0.2697\n",
            "Epoch [30/50], Batch 40, Loss: 0.1995\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [31/50], Batch 1, Loss: 0.0887\n",
            "Epoch [31/50], Batch 2, Loss: 0.2238\n",
            "Epoch [31/50], Batch 3, Loss: 0.1248\n",
            "Epoch [31/50], Batch 4, Loss: 0.1089\n",
            "Epoch [31/50], Batch 5, Loss: 0.1731\n",
            "Epoch [31/50], Batch 6, Loss: 0.1664\n",
            "Epoch [31/50], Batch 7, Loss: 0.1784\n",
            "Epoch [31/50], Batch 8, Loss: 0.1054\n",
            "Epoch [31/50], Batch 9, Loss: 0.1754\n",
            "Epoch [31/50], Batch 10, Loss: 0.2442\n",
            "Epoch [31/50], Batch 11, Loss: 0.1550\n",
            "Epoch [31/50], Batch 12, Loss: 0.0844\n",
            "Epoch [31/50], Batch 13, Loss: 0.1518\n",
            "Epoch [31/50], Batch 14, Loss: 0.1550\n",
            "Epoch [31/50], Batch 15, Loss: 0.1708\n",
            "Epoch [31/50], Batch 16, Loss: 0.1751\n",
            "Epoch [31/50], Batch 17, Loss: 0.1445\n",
            "Epoch [31/50], Batch 18, Loss: 0.1422\n",
            "Epoch [31/50], Batch 19, Loss: 0.1615\n",
            "Epoch [31/50], Batch 20, Loss: 0.1585\n",
            "Epoch [31/50], Batch 21, Loss: 0.1054\n",
            "Epoch [31/50], Batch 22, Loss: 0.1306\n",
            "Epoch [31/50], Batch 23, Loss: 0.1080\n",
            "Epoch [31/50], Batch 24, Loss: 0.1442\n",
            "Epoch [31/50], Batch 25, Loss: 0.1548\n",
            "Epoch [31/50], Batch 26, Loss: 0.2147\n",
            "Epoch [31/50], Batch 27, Loss: 0.1511\n",
            "Epoch [31/50], Batch 28, Loss: 0.1365\n",
            "Epoch [31/50], Batch 29, Loss: 0.1658\n",
            "Epoch [31/50], Batch 30, Loss: 0.1819\n",
            "Epoch [31/50], Batch 31, Loss: 0.1719\n",
            "Epoch [31/50], Batch 32, Loss: 0.1880\n",
            "Epoch [31/50], Batch 33, Loss: 0.1801\n",
            "Epoch [31/50], Batch 34, Loss: 0.1685\n",
            "Epoch [31/50], Batch 35, Loss: 0.1355\n",
            "Epoch [31/50], Batch 36, Loss: 0.1420\n",
            "Epoch [31/50], Batch 37, Loss: 0.1059\n",
            "Epoch [31/50], Batch 38, Loss: 0.1094\n",
            "Epoch [31/50], Batch 39, Loss: 0.1509\n",
            "Epoch [31/50], Batch 40, Loss: 0.1395\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [32/50], Batch 1, Loss: 0.2707\n",
            "Epoch [32/50], Batch 2, Loss: 0.1604\n",
            "Epoch [32/50], Batch 3, Loss: 0.0870\n",
            "Epoch [32/50], Batch 4, Loss: 0.1507\n",
            "Epoch [32/50], Batch 5, Loss: 0.0911\n",
            "Epoch [32/50], Batch 6, Loss: 0.1321\n",
            "Epoch [32/50], Batch 7, Loss: 0.1188\n",
            "Epoch [32/50], Batch 8, Loss: 0.0946\n",
            "Epoch [32/50], Batch 9, Loss: 0.1400\n",
            "Epoch [32/50], Batch 10, Loss: 0.1690\n",
            "Epoch [32/50], Batch 11, Loss: 0.1074\n",
            "Epoch [32/50], Batch 12, Loss: 0.0795\n",
            "Epoch [32/50], Batch 13, Loss: 0.1306\n",
            "Epoch [32/50], Batch 14, Loss: 0.1319\n",
            "Epoch [32/50], Batch 15, Loss: 0.1186\n",
            "Epoch [32/50], Batch 16, Loss: 0.1353\n",
            "Epoch [32/50], Batch 17, Loss: 0.0951\n",
            "Epoch [32/50], Batch 18, Loss: 0.1443\n",
            "Epoch [32/50], Batch 19, Loss: 0.2273\n",
            "Epoch [32/50], Batch 20, Loss: 0.0907\n",
            "Epoch [32/50], Batch 21, Loss: 0.1448\n",
            "Epoch [32/50], Batch 22, Loss: 0.1362\n",
            "Epoch [32/50], Batch 23, Loss: 0.1436\n",
            "Epoch [32/50], Batch 24, Loss: 0.1446\n",
            "Epoch [32/50], Batch 25, Loss: 0.1540\n",
            "Epoch [32/50], Batch 26, Loss: 0.1109\n",
            "Epoch [32/50], Batch 27, Loss: 0.1156\n",
            "Epoch [32/50], Batch 28, Loss: 0.0974\n",
            "Epoch [32/50], Batch 29, Loss: 0.1744\n",
            "Epoch [32/50], Batch 30, Loss: 0.1636\n",
            "Epoch [32/50], Batch 31, Loss: 0.2556\n",
            "Epoch [32/50], Batch 32, Loss: 0.1084\n",
            "Epoch [32/50], Batch 33, Loss: 0.1218\n",
            "Epoch [32/50], Batch 34, Loss: 0.1342\n",
            "Epoch [32/50], Batch 35, Loss: 0.1665\n",
            "Epoch [32/50], Batch 36, Loss: 0.2113\n",
            "Epoch [32/50], Batch 37, Loss: 0.1673\n",
            "Epoch [32/50], Batch 38, Loss: 0.0651\n",
            "Epoch [32/50], Batch 39, Loss: 0.1994\n",
            "Epoch [32/50], Batch 40, Loss: 0.1425\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [33/50], Batch 1, Loss: 0.1620\n",
            "Epoch [33/50], Batch 2, Loss: 0.1480\n",
            "Epoch [33/50], Batch 3, Loss: 0.2263\n",
            "Epoch [33/50], Batch 4, Loss: 0.0809\n",
            "Epoch [33/50], Batch 5, Loss: 0.1551\n",
            "Epoch [33/50], Batch 6, Loss: 0.1542\n",
            "Epoch [33/50], Batch 7, Loss: 0.1985\n",
            "Epoch [33/50], Batch 8, Loss: 0.2195\n",
            "Epoch [33/50], Batch 9, Loss: 0.1218\n",
            "Epoch [33/50], Batch 10, Loss: 0.2165\n",
            "Epoch [33/50], Batch 11, Loss: 0.1500\n",
            "Epoch [33/50], Batch 12, Loss: 0.1988\n",
            "Epoch [33/50], Batch 13, Loss: 0.0975\n",
            "Epoch [33/50], Batch 14, Loss: 0.2119\n",
            "Epoch [33/50], Batch 15, Loss: 0.1077\n",
            "Epoch [33/50], Batch 16, Loss: 0.1045\n",
            "Epoch [33/50], Batch 17, Loss: 0.2072\n",
            "Epoch [33/50], Batch 18, Loss: 0.4508\n",
            "Epoch [33/50], Batch 19, Loss: 0.1397\n",
            "Epoch [33/50], Batch 20, Loss: 0.1932\n",
            "Epoch [33/50], Batch 21, Loss: 0.2210\n",
            "Epoch [33/50], Batch 22, Loss: 0.1929\n",
            "Epoch [33/50], Batch 23, Loss: 0.1290\n",
            "Epoch [33/50], Batch 24, Loss: 0.1226\n",
            "Epoch [33/50], Batch 25, Loss: 0.1710\n",
            "Epoch [33/50], Batch 26, Loss: 0.1536\n",
            "Epoch [33/50], Batch 27, Loss: 0.1835\n",
            "Epoch [33/50], Batch 28, Loss: 0.1333\n",
            "Epoch [33/50], Batch 29, Loss: 0.2072\n",
            "Epoch [33/50], Batch 30, Loss: 0.1806\n",
            "Epoch [33/50], Batch 31, Loss: 0.0636\n",
            "Epoch [33/50], Batch 32, Loss: 0.1439\n",
            "Epoch [33/50], Batch 33, Loss: 0.0982\n",
            "Epoch [33/50], Batch 34, Loss: 0.1567\n",
            "Epoch [33/50], Batch 35, Loss: 0.1680\n",
            "Epoch [33/50], Batch 36, Loss: 0.2648\n",
            "Epoch [33/50], Batch 37, Loss: 0.1383\n",
            "Epoch [33/50], Batch 38, Loss: 0.1214\n",
            "Epoch [33/50], Batch 39, Loss: 0.1072\n",
            "Epoch [33/50], Batch 40, Loss: 0.1832\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [34/50], Batch 1, Loss: 0.1486\n",
            "Epoch [34/50], Batch 2, Loss: 0.2059\n",
            "Epoch [34/50], Batch 3, Loss: 0.0974\n",
            "Epoch [34/50], Batch 4, Loss: 0.1572\n",
            "Epoch [34/50], Batch 5, Loss: 0.0881\n",
            "Epoch [34/50], Batch 6, Loss: 0.1980\n",
            "Epoch [34/50], Batch 7, Loss: 0.1532\n",
            "Epoch [34/50], Batch 8, Loss: 0.0902\n",
            "Epoch [34/50], Batch 9, Loss: 0.1622\n",
            "Epoch [34/50], Batch 10, Loss: 0.1492\n",
            "Epoch [34/50], Batch 11, Loss: 0.1202\n",
            "Epoch [34/50], Batch 12, Loss: 0.1742\n",
            "Epoch [34/50], Batch 13, Loss: 0.1166\n",
            "Epoch [34/50], Batch 14, Loss: 0.1609\n",
            "Epoch [34/50], Batch 15, Loss: 0.0769\n",
            "Epoch [34/50], Batch 16, Loss: 0.1247\n",
            "Epoch [34/50], Batch 17, Loss: 0.1180\n",
            "Epoch [34/50], Batch 18, Loss: 0.2118\n",
            "Epoch [34/50], Batch 19, Loss: 0.1276\n",
            "Epoch [34/50], Batch 20, Loss: 0.1600\n",
            "Epoch [34/50], Batch 21, Loss: 0.1807\n",
            "Epoch [34/50], Batch 22, Loss: 0.1160\n",
            "Epoch [34/50], Batch 23, Loss: 0.1562\n",
            "Epoch [34/50], Batch 24, Loss: 0.1495\n",
            "Epoch [34/50], Batch 25, Loss: 0.1960\n",
            "Epoch [34/50], Batch 26, Loss: 0.1348\n",
            "Epoch [34/50], Batch 27, Loss: 0.1335\n",
            "Epoch [34/50], Batch 28, Loss: 0.1734\n",
            "Epoch [34/50], Batch 29, Loss: 0.1054\n",
            "Epoch [34/50], Batch 30, Loss: 0.1962\n",
            "Epoch [34/50], Batch 31, Loss: 0.0996\n",
            "Epoch [34/50], Batch 32, Loss: 0.1667\n",
            "Epoch [34/50], Batch 33, Loss: 0.2536\n",
            "Epoch [34/50], Batch 34, Loss: 0.0998\n",
            "Epoch [34/50], Batch 35, Loss: 0.1469\n",
            "Epoch [34/50], Batch 36, Loss: 0.1446\n",
            "Epoch [34/50], Batch 37, Loss: 0.2100\n",
            "Epoch [34/50], Batch 38, Loss: 0.1469\n",
            "Epoch [34/50], Batch 39, Loss: 0.1979\n",
            "Epoch [34/50], Batch 40, Loss: 0.1541\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [35/50], Batch 1, Loss: 0.2147\n",
            "Epoch [35/50], Batch 2, Loss: 0.1201\n",
            "Epoch [35/50], Batch 3, Loss: 0.1198\n",
            "Epoch [35/50], Batch 4, Loss: 0.1731\n",
            "Epoch [35/50], Batch 5, Loss: 0.1058\n",
            "Epoch [35/50], Batch 6, Loss: 0.1508\n",
            "Epoch [35/50], Batch 7, Loss: 0.1463\n",
            "Epoch [35/50], Batch 8, Loss: 0.1387\n",
            "Epoch [35/50], Batch 9, Loss: 0.2963\n",
            "Epoch [35/50], Batch 10, Loss: 0.1222\n",
            "Epoch [35/50], Batch 11, Loss: 0.1374\n",
            "Epoch [35/50], Batch 12, Loss: 0.1022\n",
            "Epoch [35/50], Batch 13, Loss: 0.1698\n",
            "Epoch [35/50], Batch 14, Loss: 0.1642\n",
            "Epoch [35/50], Batch 15, Loss: 0.1867\n",
            "Epoch [35/50], Batch 16, Loss: 0.1673\n",
            "Epoch [35/50], Batch 17, Loss: 0.1286\n",
            "Epoch [35/50], Batch 18, Loss: 0.1580\n",
            "Epoch [35/50], Batch 19, Loss: 0.0860\n",
            "Epoch [35/50], Batch 20, Loss: 0.1363\n",
            "Epoch [35/50], Batch 21, Loss: 0.1498\n",
            "Epoch [35/50], Batch 22, Loss: 0.1066\n",
            "Epoch [35/50], Batch 23, Loss: 0.0922\n",
            "Epoch [35/50], Batch 24, Loss: 0.1501\n",
            "Epoch [35/50], Batch 25, Loss: 0.1099\n",
            "Epoch [35/50], Batch 26, Loss: 0.1124\n",
            "Epoch [35/50], Batch 27, Loss: 0.0680\n",
            "Epoch [35/50], Batch 28, Loss: 0.1624\n",
            "Epoch [35/50], Batch 29, Loss: 0.1340\n",
            "Epoch [35/50], Batch 30, Loss: 0.1710\n",
            "Epoch [35/50], Batch 31, Loss: 0.0941\n",
            "Epoch [35/50], Batch 32, Loss: 0.0941\n",
            "Epoch [35/50], Batch 33, Loss: 0.1517\n",
            "Epoch [35/50], Batch 34, Loss: 0.0933\n",
            "Epoch [35/50], Batch 35, Loss: 0.1091\n",
            "Epoch [35/50], Batch 36, Loss: 0.1622\n",
            "Epoch [35/50], Batch 37, Loss: 0.1017\n",
            "Epoch [35/50], Batch 38, Loss: 0.1637\n",
            "Epoch [35/50], Batch 39, Loss: 0.1766\n",
            "Epoch [35/50], Batch 40, Loss: 0.1890\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [36/50], Batch 1, Loss: 0.1357\n",
            "Epoch [36/50], Batch 2, Loss: 0.1601\n",
            "Epoch [36/50], Batch 3, Loss: 0.2480\n",
            "Epoch [36/50], Batch 4, Loss: 0.1204\n",
            "Epoch [36/50], Batch 5, Loss: 0.3867\n",
            "Epoch [36/50], Batch 6, Loss: 0.1838\n",
            "Epoch [36/50], Batch 7, Loss: 0.1803\n",
            "Epoch [36/50], Batch 8, Loss: 0.1827\n",
            "Epoch [36/50], Batch 9, Loss: 0.1056\n",
            "Epoch [36/50], Batch 10, Loss: 0.1004\n",
            "Epoch [36/50], Batch 11, Loss: 0.1387\n",
            "Epoch [36/50], Batch 12, Loss: 0.1901\n",
            "Epoch [36/50], Batch 13, Loss: 0.1027\n",
            "Epoch [36/50], Batch 14, Loss: 0.1146\n",
            "Epoch [36/50], Batch 15, Loss: 0.2066\n",
            "Epoch [36/50], Batch 16, Loss: 0.1576\n",
            "Epoch [36/50], Batch 17, Loss: 0.1612\n",
            "Epoch [36/50], Batch 18, Loss: 0.1967\n",
            "Epoch [36/50], Batch 19, Loss: 0.2147\n",
            "Epoch [36/50], Batch 20, Loss: 0.1361\n",
            "Epoch [36/50], Batch 21, Loss: 0.0732\n",
            "Epoch [36/50], Batch 22, Loss: 0.1381\n",
            "Epoch [36/50], Batch 23, Loss: 0.1714\n",
            "Epoch [36/50], Batch 24, Loss: 0.1382\n",
            "Epoch [36/50], Batch 25, Loss: 0.1378\n",
            "Epoch [36/50], Batch 26, Loss: 0.2258\n",
            "Epoch [36/50], Batch 27, Loss: 0.1301\n",
            "Epoch [36/50], Batch 28, Loss: 0.1371\n",
            "Epoch [36/50], Batch 29, Loss: 0.1366\n",
            "Epoch [36/50], Batch 30, Loss: 0.1831\n",
            "Epoch [36/50], Batch 31, Loss: 0.1796\n",
            "Epoch [36/50], Batch 32, Loss: 0.2196\n",
            "Epoch [36/50], Batch 33, Loss: 0.1004\n",
            "Epoch [36/50], Batch 34, Loss: 0.1210\n",
            "Epoch [36/50], Batch 35, Loss: 0.1250\n",
            "Epoch [36/50], Batch 36, Loss: 0.2071\n",
            "Epoch [36/50], Batch 37, Loss: 0.1751\n",
            "Epoch [36/50], Batch 38, Loss: 0.1941\n",
            "Epoch [36/50], Batch 39, Loss: 0.1368\n",
            "Epoch [36/50], Batch 40, Loss: 0.1068\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [37/50], Batch 1, Loss: 0.0932\n",
            "Epoch [37/50], Batch 2, Loss: 0.2127\n",
            "Epoch [37/50], Batch 3, Loss: 0.1371\n",
            "Epoch [37/50], Batch 4, Loss: 0.1260\n",
            "Epoch [37/50], Batch 5, Loss: 0.1565\n",
            "Epoch [37/50], Batch 6, Loss: 0.1431\n",
            "Epoch [37/50], Batch 7, Loss: 0.2233\n",
            "Epoch [37/50], Batch 8, Loss: 0.1442\n",
            "Epoch [37/50], Batch 9, Loss: 0.0779\n",
            "Epoch [37/50], Batch 10, Loss: 0.1611\n",
            "Epoch [37/50], Batch 11, Loss: 0.1968\n",
            "Epoch [37/50], Batch 12, Loss: 0.1253\n",
            "Epoch [37/50], Batch 13, Loss: 0.1514\n",
            "Epoch [37/50], Batch 14, Loss: 0.1333\n",
            "Epoch [37/50], Batch 15, Loss: 0.1084\n",
            "Epoch [37/50], Batch 16, Loss: 0.1261\n",
            "Epoch [37/50], Batch 17, Loss: 0.1133\n",
            "Epoch [37/50], Batch 18, Loss: 0.1662\n",
            "Epoch [37/50], Batch 19, Loss: 0.1699\n",
            "Epoch [37/50], Batch 20, Loss: 0.1483\n",
            "Epoch [37/50], Batch 21, Loss: 0.1785\n",
            "Epoch [37/50], Batch 22, Loss: 0.1642\n",
            "Epoch [37/50], Batch 23, Loss: 0.0989\n",
            "Epoch [37/50], Batch 24, Loss: 0.1155\n",
            "Epoch [37/50], Batch 25, Loss: 0.0991\n",
            "Epoch [37/50], Batch 26, Loss: 0.1051\n",
            "Epoch [37/50], Batch 27, Loss: 0.2378\n",
            "Epoch [37/50], Batch 28, Loss: 0.1816\n",
            "Epoch [37/50], Batch 29, Loss: 0.0655\n",
            "Epoch [37/50], Batch 30, Loss: 0.2034\n",
            "Epoch [37/50], Batch 31, Loss: 0.2462\n",
            "Epoch [37/50], Batch 32, Loss: 0.1890\n",
            "Epoch [37/50], Batch 33, Loss: 0.1435\n",
            "Epoch [37/50], Batch 34, Loss: 0.1294\n",
            "Epoch [37/50], Batch 35, Loss: 0.1495\n",
            "Epoch [37/50], Batch 36, Loss: 0.1974\n",
            "Epoch [37/50], Batch 37, Loss: 0.1170\n",
            "Epoch [37/50], Batch 38, Loss: 0.1187\n",
            "Epoch [37/50], Batch 39, Loss: 0.1912\n",
            "Epoch [37/50], Batch 40, Loss: 0.1343\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [38/50], Batch 1, Loss: 0.1500\n",
            "Epoch [38/50], Batch 2, Loss: 0.0885\n",
            "Epoch [38/50], Batch 3, Loss: 0.1055\n",
            "Epoch [38/50], Batch 4, Loss: 0.1079\n",
            "Epoch [38/50], Batch 5, Loss: 0.0758\n",
            "Epoch [38/50], Batch 6, Loss: 0.0952\n",
            "Epoch [38/50], Batch 7, Loss: 0.1132\n",
            "Epoch [38/50], Batch 8, Loss: 0.0973\n",
            "Epoch [38/50], Batch 9, Loss: 0.1235\n",
            "Epoch [38/50], Batch 10, Loss: 0.0657\n",
            "Epoch [38/50], Batch 11, Loss: 0.0995\n",
            "Epoch [38/50], Batch 12, Loss: 0.1827\n",
            "Epoch [38/50], Batch 13, Loss: 0.1334\n",
            "Epoch [38/50], Batch 14, Loss: 0.1542\n",
            "Epoch [38/50], Batch 15, Loss: 0.1190\n",
            "Epoch [38/50], Batch 16, Loss: 0.1241\n",
            "Epoch [38/50], Batch 17, Loss: 0.1139\n",
            "Epoch [38/50], Batch 18, Loss: 0.1781\n",
            "Epoch [38/50], Batch 19, Loss: 0.1331\n",
            "Epoch [38/50], Batch 20, Loss: 0.1972\n",
            "Epoch [38/50], Batch 21, Loss: 0.1645\n",
            "Epoch [38/50], Batch 22, Loss: 0.2229\n",
            "Epoch [38/50], Batch 23, Loss: 0.1410\n",
            "Epoch [38/50], Batch 24, Loss: 0.1892\n",
            "Epoch [38/50], Batch 25, Loss: 0.1858\n",
            "Epoch [38/50], Batch 26, Loss: 0.0967\n",
            "Epoch [38/50], Batch 27, Loss: 0.2147\n",
            "Epoch [38/50], Batch 28, Loss: 0.1247\n",
            "Epoch [38/50], Batch 29, Loss: 0.2012\n",
            "Epoch [38/50], Batch 30, Loss: 0.1072\n",
            "Epoch [38/50], Batch 31, Loss: 0.0855\n",
            "Epoch [38/50], Batch 32, Loss: 0.1136\n",
            "Epoch [38/50], Batch 33, Loss: 0.1578\n",
            "Epoch [38/50], Batch 34, Loss: 0.1207\n",
            "Epoch [38/50], Batch 35, Loss: 0.1557\n",
            "Epoch [38/50], Batch 36, Loss: 0.2267\n",
            "Epoch [38/50], Batch 37, Loss: 0.0813\n",
            "Epoch [38/50], Batch 38, Loss: 0.1446\n",
            "Epoch [38/50], Batch 39, Loss: 0.1145\n",
            "Epoch [38/50], Batch 40, Loss: 0.1604\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [39/50], Batch 1, Loss: 0.1601\n",
            "Epoch [39/50], Batch 2, Loss: 0.1129\n",
            "Epoch [39/50], Batch 3, Loss: 0.1147\n",
            "Epoch [39/50], Batch 4, Loss: 0.1260\n",
            "Epoch [39/50], Batch 5, Loss: 0.1110\n",
            "Epoch [39/50], Batch 6, Loss: 0.1196\n",
            "Epoch [39/50], Batch 7, Loss: 0.1341\n",
            "Epoch [39/50], Batch 8, Loss: 0.0839\n",
            "Epoch [39/50], Batch 9, Loss: 0.1763\n",
            "Epoch [39/50], Batch 10, Loss: 0.1210\n",
            "Epoch [39/50], Batch 11, Loss: 0.0867\n",
            "Epoch [39/50], Batch 12, Loss: 0.0957\n",
            "Epoch [39/50], Batch 13, Loss: 0.0869\n",
            "Epoch [39/50], Batch 14, Loss: 0.1450\n",
            "Epoch [39/50], Batch 15, Loss: 0.1461\n",
            "Epoch [39/50], Batch 16, Loss: 0.1551\n",
            "Epoch [39/50], Batch 17, Loss: 0.1523\n",
            "Epoch [39/50], Batch 18, Loss: 0.0878\n",
            "Epoch [39/50], Batch 19, Loss: 0.0823\n",
            "Epoch [39/50], Batch 20, Loss: 0.1186\n",
            "Epoch [39/50], Batch 21, Loss: 0.0842\n",
            "Epoch [39/50], Batch 22, Loss: 0.0760\n",
            "Epoch [39/50], Batch 23, Loss: 0.1058\n",
            "Epoch [39/50], Batch 24, Loss: 0.0529\n",
            "Epoch [39/50], Batch 25, Loss: 0.1414\n",
            "Epoch [39/50], Batch 26, Loss: 0.1366\n",
            "Epoch [39/50], Batch 27, Loss: 0.1275\n",
            "Epoch [39/50], Batch 28, Loss: 0.1301\n",
            "Epoch [39/50], Batch 29, Loss: 0.1240\n",
            "Epoch [39/50], Batch 30, Loss: 0.1483\n",
            "Epoch [39/50], Batch 31, Loss: 0.1047\n",
            "Epoch [39/50], Batch 32, Loss: 0.1378\n",
            "Epoch [39/50], Batch 33, Loss: 0.1607\n",
            "Epoch [39/50], Batch 34, Loss: 0.0690\n",
            "Epoch [39/50], Batch 35, Loss: 0.1416\n",
            "Epoch [39/50], Batch 36, Loss: 0.1128\n",
            "Epoch [39/50], Batch 37, Loss: 0.1714\n",
            "Epoch [39/50], Batch 38, Loss: 0.1683\n",
            "Epoch [39/50], Batch 39, Loss: 0.1730\n",
            "Epoch [39/50], Batch 40, Loss: 0.1267\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [40/50], Batch 1, Loss: 0.0988\n",
            "Epoch [40/50], Batch 2, Loss: 0.1445\n",
            "Epoch [40/50], Batch 3, Loss: 0.1022\n",
            "Epoch [40/50], Batch 4, Loss: 0.0666\n",
            "Epoch [40/50], Batch 5, Loss: 0.0844\n",
            "Epoch [40/50], Batch 6, Loss: 0.0881\n",
            "Epoch [40/50], Batch 7, Loss: 0.1451\n",
            "Epoch [40/50], Batch 8, Loss: 0.1283\n",
            "Epoch [40/50], Batch 9, Loss: 0.1075\n",
            "Epoch [40/50], Batch 10, Loss: 0.2030\n",
            "Epoch [40/50], Batch 11, Loss: 0.1306\n",
            "Epoch [40/50], Batch 12, Loss: 0.1415\n",
            "Epoch [40/50], Batch 13, Loss: 0.2180\n",
            "Epoch [40/50], Batch 14, Loss: 0.2297\n",
            "Epoch [40/50], Batch 15, Loss: 0.1743\n",
            "Epoch [40/50], Batch 16, Loss: 0.1627\n",
            "Epoch [40/50], Batch 17, Loss: 0.0979\n",
            "Epoch [40/50], Batch 18, Loss: 0.1071\n",
            "Epoch [40/50], Batch 19, Loss: 0.1070\n",
            "Epoch [40/50], Batch 20, Loss: 0.1643\n",
            "Epoch [40/50], Batch 21, Loss: 0.1773\n",
            "Epoch [40/50], Batch 22, Loss: 0.1277\n",
            "Epoch [40/50], Batch 23, Loss: 0.2079\n",
            "Epoch [40/50], Batch 24, Loss: 0.0996\n",
            "Epoch [40/50], Batch 25, Loss: 0.1349\n",
            "Epoch [40/50], Batch 26, Loss: 0.1320\n",
            "Epoch [40/50], Batch 27, Loss: 0.1428\n",
            "Epoch [40/50], Batch 28, Loss: 0.1645\n",
            "Epoch [40/50], Batch 29, Loss: 0.2389\n",
            "Epoch [40/50], Batch 30, Loss: 0.1001\n",
            "Epoch [40/50], Batch 31, Loss: 0.1272\n",
            "Epoch [40/50], Batch 32, Loss: 0.1384\n",
            "Epoch [40/50], Batch 33, Loss: 0.1934\n",
            "Epoch [40/50], Batch 34, Loss: 0.0952\n",
            "Epoch [40/50], Batch 35, Loss: 0.1259\n",
            "Epoch [40/50], Batch 36, Loss: 0.1205\n",
            "Epoch [40/50], Batch 37, Loss: 0.0614\n",
            "Epoch [40/50], Batch 38, Loss: 0.1395\n",
            "Epoch [40/50], Batch 39, Loss: 0.2282\n",
            "Epoch [40/50], Batch 40, Loss: 0.1318\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [41/50], Batch 1, Loss: 0.1072\n",
            "Epoch [41/50], Batch 2, Loss: 0.0753\n",
            "Epoch [41/50], Batch 3, Loss: 0.0866\n",
            "Epoch [41/50], Batch 4, Loss: 0.1470\n",
            "Epoch [41/50], Batch 5, Loss: 0.1399\n",
            "Epoch [41/50], Batch 6, Loss: 0.1904\n",
            "Epoch [41/50], Batch 7, Loss: 0.1600\n",
            "Epoch [41/50], Batch 8, Loss: 0.0954\n",
            "Epoch [41/50], Batch 9, Loss: 0.0673\n",
            "Epoch [41/50], Batch 10, Loss: 0.0790\n",
            "Epoch [41/50], Batch 11, Loss: 0.1152\n",
            "Epoch [41/50], Batch 12, Loss: 0.1389\n",
            "Epoch [41/50], Batch 13, Loss: 0.2082\n",
            "Epoch [41/50], Batch 14, Loss: 0.1088\n",
            "Epoch [41/50], Batch 15, Loss: 0.1242\n",
            "Epoch [41/50], Batch 16, Loss: 0.1470\n",
            "Epoch [41/50], Batch 17, Loss: 0.0483\n",
            "Epoch [41/50], Batch 18, Loss: 0.0935\n",
            "Epoch [41/50], Batch 19, Loss: 0.1656\n",
            "Epoch [41/50], Batch 20, Loss: 0.1137\n",
            "Epoch [41/50], Batch 21, Loss: 0.1137\n",
            "Epoch [41/50], Batch 22, Loss: 0.1051\n",
            "Epoch [41/50], Batch 23, Loss: 0.1301\n",
            "Epoch [41/50], Batch 24, Loss: 0.1606\n",
            "Epoch [41/50], Batch 25, Loss: 0.2390\n",
            "Epoch [41/50], Batch 26, Loss: 0.1549\n",
            "Epoch [41/50], Batch 27, Loss: 0.2069\n",
            "Epoch [41/50], Batch 28, Loss: 0.0959\n",
            "Epoch [41/50], Batch 29, Loss: 0.1041\n",
            "Epoch [41/50], Batch 30, Loss: 0.1275\n",
            "Epoch [41/50], Batch 31, Loss: 0.1791\n",
            "Epoch [41/50], Batch 32, Loss: 0.1523\n",
            "Epoch [41/50], Batch 33, Loss: 0.1059\n",
            "Epoch [41/50], Batch 34, Loss: 0.1437\n",
            "Epoch [41/50], Batch 35, Loss: 0.2153\n",
            "Epoch [41/50], Batch 36, Loss: 0.1300\n",
            "Epoch [41/50], Batch 37, Loss: 0.2163\n",
            "Epoch [41/50], Batch 38, Loss: 0.1512\n",
            "Epoch [41/50], Batch 39, Loss: 0.1827\n",
            "Epoch [41/50], Batch 40, Loss: 0.1576\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [42/50], Batch 1, Loss: 0.1980\n",
            "Epoch [42/50], Batch 2, Loss: 0.1620\n",
            "Epoch [42/50], Batch 3, Loss: 0.1652\n",
            "Epoch [42/50], Batch 4, Loss: 0.0595\n",
            "Epoch [42/50], Batch 5, Loss: 0.1582\n",
            "Epoch [42/50], Batch 6, Loss: 0.1087\n",
            "Epoch [42/50], Batch 7, Loss: 0.1219\n",
            "Epoch [42/50], Batch 8, Loss: 0.0785\n",
            "Epoch [42/50], Batch 9, Loss: 0.2167\n",
            "Epoch [42/50], Batch 10, Loss: 0.0763\n",
            "Epoch [42/50], Batch 11, Loss: 0.1837\n",
            "Epoch [42/50], Batch 12, Loss: 0.1780\n",
            "Epoch [42/50], Batch 13, Loss: 0.1706\n",
            "Epoch [42/50], Batch 14, Loss: 0.0925\n",
            "Epoch [42/50], Batch 15, Loss: 0.1767\n",
            "Epoch [42/50], Batch 16, Loss: 0.1781\n",
            "Epoch [42/50], Batch 17, Loss: 0.1692\n",
            "Epoch [42/50], Batch 18, Loss: 0.1337\n",
            "Epoch [42/50], Batch 19, Loss: 0.1025\n",
            "Epoch [42/50], Batch 20, Loss: 0.1244\n",
            "Epoch [42/50], Batch 21, Loss: 0.1337\n",
            "Epoch [42/50], Batch 22, Loss: 0.1549\n",
            "Epoch [42/50], Batch 23, Loss: 0.1061\n",
            "Epoch [42/50], Batch 24, Loss: 0.0858\n",
            "Epoch [42/50], Batch 25, Loss: 0.1126\n",
            "Epoch [42/50], Batch 26, Loss: 0.0555\n",
            "Epoch [42/50], Batch 27, Loss: 0.1208\n",
            "Epoch [42/50], Batch 28, Loss: 0.0750\n",
            "Epoch [42/50], Batch 29, Loss: 0.0945\n",
            "Epoch [42/50], Batch 30, Loss: 0.1584\n",
            "Epoch [42/50], Batch 31, Loss: 0.2039\n",
            "Epoch [42/50], Batch 32, Loss: 0.0668\n",
            "Epoch [42/50], Batch 33, Loss: 0.0867\n",
            "Epoch [42/50], Batch 34, Loss: 0.1398\n",
            "Epoch [42/50], Batch 35, Loss: 0.0886\n",
            "Epoch [42/50], Batch 36, Loss: 0.1140\n",
            "Epoch [42/50], Batch 37, Loss: 0.1292\n",
            "Epoch [42/50], Batch 38, Loss: 0.1500\n",
            "Epoch [42/50], Batch 39, Loss: 0.1076\n",
            "Epoch [42/50], Batch 40, Loss: 0.1656\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [43/50], Batch 1, Loss: 0.0609\n",
            "Epoch [43/50], Batch 2, Loss: 0.0493\n",
            "Epoch [43/50], Batch 3, Loss: 0.0412\n",
            "Epoch [43/50], Batch 4, Loss: 0.1096\n",
            "Epoch [43/50], Batch 5, Loss: 0.1088\n",
            "Epoch [43/50], Batch 6, Loss: 0.0716\n",
            "Epoch [43/50], Batch 7, Loss: 0.0991\n",
            "Epoch [43/50], Batch 8, Loss: 0.0916\n",
            "Epoch [43/50], Batch 9, Loss: 0.0672\n",
            "Epoch [43/50], Batch 10, Loss: 0.1012\n",
            "Epoch [43/50], Batch 11, Loss: 0.1389\n",
            "Epoch [43/50], Batch 12, Loss: 0.1123\n",
            "Epoch [43/50], Batch 13, Loss: 0.1059\n",
            "Epoch [43/50], Batch 14, Loss: 0.1555\n",
            "Epoch [43/50], Batch 15, Loss: 0.0559\n",
            "Epoch [43/50], Batch 16, Loss: 0.1158\n",
            "Epoch [43/50], Batch 17, Loss: 0.1398\n",
            "Epoch [43/50], Batch 18, Loss: 0.1695\n",
            "Epoch [43/50], Batch 19, Loss: 0.1089\n",
            "Epoch [43/50], Batch 20, Loss: 0.1100\n",
            "Epoch [43/50], Batch 21, Loss: 0.1303\n",
            "Epoch [43/50], Batch 22, Loss: 0.1589\n",
            "Epoch [43/50], Batch 23, Loss: 0.2143\n",
            "Epoch [43/50], Batch 24, Loss: 0.2282\n",
            "Epoch [43/50], Batch 25, Loss: 0.1961\n",
            "Epoch [43/50], Batch 26, Loss: 0.1574\n",
            "Epoch [43/50], Batch 27, Loss: 0.1337\n",
            "Epoch [43/50], Batch 28, Loss: 0.1176\n",
            "Epoch [43/50], Batch 29, Loss: 0.1049\n",
            "Epoch [43/50], Batch 30, Loss: 0.1317\n",
            "Epoch [43/50], Batch 31, Loss: 0.1562\n",
            "Epoch [43/50], Batch 32, Loss: 0.1697\n",
            "Epoch [43/50], Batch 33, Loss: 0.2516\n",
            "Epoch [43/50], Batch 34, Loss: 0.0635\n",
            "Epoch [43/50], Batch 35, Loss: 0.0944\n",
            "Epoch [43/50], Batch 36, Loss: 0.1603\n",
            "Epoch [43/50], Batch 37, Loss: 0.2225\n",
            "Epoch [43/50], Batch 38, Loss: 0.1008\n",
            "Epoch [43/50], Batch 39, Loss: 0.0759\n",
            "Epoch [43/50], Batch 40, Loss: 0.1528\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [44/50], Batch 1, Loss: 0.1852\n",
            "Epoch [44/50], Batch 2, Loss: 0.1066\n",
            "Epoch [44/50], Batch 3, Loss: 0.1171\n",
            "Epoch [44/50], Batch 4, Loss: 0.0660\n",
            "Epoch [44/50], Batch 5, Loss: 0.3058\n",
            "Epoch [44/50], Batch 6, Loss: 0.1303\n",
            "Epoch [44/50], Batch 7, Loss: 0.0750\n",
            "Epoch [44/50], Batch 8, Loss: 0.1463\n",
            "Epoch [44/50], Batch 9, Loss: 0.1098\n",
            "Epoch [44/50], Batch 10, Loss: 0.1724\n",
            "Epoch [44/50], Batch 11, Loss: 0.1052\n",
            "Epoch [44/50], Batch 12, Loss: 0.1914\n",
            "Epoch [44/50], Batch 13, Loss: 0.2373\n",
            "Epoch [44/50], Batch 14, Loss: 0.1280\n",
            "Epoch [44/50], Batch 15, Loss: 0.0691\n",
            "Epoch [44/50], Batch 16, Loss: 0.1143\n",
            "Epoch [44/50], Batch 17, Loss: 0.1154\n",
            "Epoch [44/50], Batch 18, Loss: 0.1212\n",
            "Epoch [44/50], Batch 19, Loss: 0.0759\n",
            "Epoch [44/50], Batch 20, Loss: 0.1693\n",
            "Epoch [44/50], Batch 21, Loss: 0.1526\n",
            "Epoch [44/50], Batch 22, Loss: 0.0482\n",
            "Epoch [44/50], Batch 23, Loss: 0.1237\n",
            "Epoch [44/50], Batch 24, Loss: 0.1270\n",
            "Epoch [44/50], Batch 25, Loss: 0.1068\n",
            "Epoch [44/50], Batch 26, Loss: 0.1241\n",
            "Epoch [44/50], Batch 27, Loss: 0.1757\n",
            "Epoch [44/50], Batch 28, Loss: 0.1033\n",
            "Epoch [44/50], Batch 29, Loss: 0.1173\n",
            "Epoch [44/50], Batch 30, Loss: 0.0605\n",
            "Epoch [44/50], Batch 31, Loss: 0.0903\n",
            "Epoch [44/50], Batch 32, Loss: 0.1228\n",
            "Epoch [44/50], Batch 33, Loss: 0.0728\n",
            "Epoch [44/50], Batch 34, Loss: 0.0943\n",
            "Epoch [44/50], Batch 35, Loss: 0.0752\n",
            "Epoch [44/50], Batch 36, Loss: 0.0642\n",
            "Epoch [44/50], Batch 37, Loss: 0.1689\n",
            "Epoch [44/50], Batch 38, Loss: 0.0901\n",
            "Epoch [44/50], Batch 39, Loss: 0.1015\n",
            "Epoch [44/50], Batch 40, Loss: 0.1144\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [45/50], Batch 1, Loss: 0.1457\n",
            "Epoch [45/50], Batch 2, Loss: 0.0710\n",
            "Epoch [45/50], Batch 3, Loss: 0.0861\n",
            "Epoch [45/50], Batch 4, Loss: 0.1066\n",
            "Epoch [45/50], Batch 5, Loss: 0.0637\n",
            "Epoch [45/50], Batch 6, Loss: 0.1106\n",
            "Epoch [45/50], Batch 7, Loss: 0.0828\n",
            "Epoch [45/50], Batch 8, Loss: 0.0931\n",
            "Epoch [45/50], Batch 9, Loss: 0.0804\n",
            "Epoch [45/50], Batch 10, Loss: 0.1253\n",
            "Epoch [45/50], Batch 11, Loss: 0.0610\n",
            "Epoch [45/50], Batch 12, Loss: 0.0835\n",
            "Epoch [45/50], Batch 13, Loss: 0.0893\n",
            "Epoch [45/50], Batch 14, Loss: 0.1101\n",
            "Epoch [45/50], Batch 15, Loss: 0.2119\n",
            "Epoch [45/50], Batch 16, Loss: 0.0954\n",
            "Epoch [45/50], Batch 17, Loss: 0.1167\n",
            "Epoch [45/50], Batch 18, Loss: 0.0853\n",
            "Epoch [45/50], Batch 19, Loss: 0.1128\n",
            "Epoch [45/50], Batch 20, Loss: 0.1251\n",
            "Epoch [45/50], Batch 21, Loss: 0.1250\n",
            "Epoch [45/50], Batch 22, Loss: 0.0520\n",
            "Epoch [45/50], Batch 23, Loss: 0.1032\n",
            "Epoch [45/50], Batch 24, Loss: 0.0953\n",
            "Epoch [45/50], Batch 25, Loss: 0.1428\n",
            "Epoch [45/50], Batch 26, Loss: 0.1420\n",
            "Epoch [45/50], Batch 27, Loss: 0.1464\n",
            "Epoch [45/50], Batch 28, Loss: 0.0766\n",
            "Epoch [45/50], Batch 29, Loss: 0.1197\n",
            "Epoch [45/50], Batch 30, Loss: 0.0813\n",
            "Epoch [45/50], Batch 31, Loss: 0.0823\n",
            "Epoch [45/50], Batch 32, Loss: 0.1140\n",
            "Epoch [45/50], Batch 33, Loss: 0.1182\n",
            "Epoch [45/50], Batch 34, Loss: 0.0918\n",
            "Epoch [45/50], Batch 35, Loss: 0.0734\n",
            "Epoch [45/50], Batch 36, Loss: 0.1012\n",
            "Epoch [45/50], Batch 37, Loss: 0.1730\n",
            "Epoch [45/50], Batch 38, Loss: 0.0954\n",
            "Epoch [45/50], Batch 39, Loss: 0.1322\n",
            "Epoch [45/50], Batch 40, Loss: 0.1500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [46/50], Batch 1, Loss: 0.0699\n",
            "Epoch [46/50], Batch 2, Loss: 0.0860\n",
            "Epoch [46/50], Batch 3, Loss: 0.0962\n",
            "Epoch [46/50], Batch 4, Loss: 0.1564\n",
            "Epoch [46/50], Batch 5, Loss: 0.1273\n",
            "Epoch [46/50], Batch 6, Loss: 0.0463\n",
            "Epoch [46/50], Batch 7, Loss: 0.0749\n",
            "Epoch [46/50], Batch 8, Loss: 0.0578\n",
            "Epoch [46/50], Batch 9, Loss: 0.0727\n",
            "Epoch [46/50], Batch 10, Loss: 0.0614\n",
            "Epoch [46/50], Batch 11, Loss: 0.1807\n",
            "Epoch [46/50], Batch 12, Loss: 0.0923\n",
            "Epoch [46/50], Batch 13, Loss: 0.1546\n",
            "Epoch [46/50], Batch 14, Loss: 0.1424\n",
            "Epoch [46/50], Batch 15, Loss: 0.0593\n",
            "Epoch [46/50], Batch 16, Loss: 0.0719\n",
            "Epoch [46/50], Batch 17, Loss: 0.0867\n",
            "Epoch [46/50], Batch 18, Loss: 0.1225\n",
            "Epoch [46/50], Batch 19, Loss: 0.1619\n",
            "Epoch [46/50], Batch 20, Loss: 0.1058\n",
            "Epoch [46/50], Batch 21, Loss: 0.1817\n",
            "Epoch [46/50], Batch 22, Loss: 0.1190\n",
            "Epoch [46/50], Batch 23, Loss: 0.2161\n",
            "Epoch [46/50], Batch 24, Loss: 0.1598\n",
            "Epoch [46/50], Batch 25, Loss: 0.1106\n",
            "Epoch [46/50], Batch 26, Loss: 0.1000\n",
            "Epoch [46/50], Batch 27, Loss: 0.1353\n",
            "Epoch [46/50], Batch 28, Loss: 0.1226\n",
            "Epoch [46/50], Batch 29, Loss: 0.1227\n",
            "Epoch [46/50], Batch 30, Loss: 0.0826\n",
            "Epoch [46/50], Batch 31, Loss: 0.1249\n",
            "Epoch [46/50], Batch 32, Loss: 0.0923\n",
            "Epoch [46/50], Batch 33, Loss: 0.0860\n",
            "Epoch [46/50], Batch 34, Loss: 0.1030\n",
            "Epoch [46/50], Batch 35, Loss: 0.0767\n",
            "Epoch [46/50], Batch 36, Loss: 0.2081\n",
            "Epoch [46/50], Batch 37, Loss: 0.1758\n",
            "Epoch [46/50], Batch 38, Loss: 0.1938\n",
            "Epoch [46/50], Batch 39, Loss: 0.1974\n",
            "Epoch [46/50], Batch 40, Loss: 0.1977\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [47/50], Batch 1, Loss: 0.1072\n",
            "Epoch [47/50], Batch 2, Loss: 0.1118\n",
            "Epoch [47/50], Batch 3, Loss: 0.1543\n",
            "Epoch [47/50], Batch 4, Loss: 0.2914\n",
            "Epoch [47/50], Batch 5, Loss: 0.1252\n",
            "Epoch [47/50], Batch 6, Loss: 0.1437\n",
            "Epoch [47/50], Batch 7, Loss: 0.1403\n",
            "Epoch [47/50], Batch 8, Loss: 0.2686\n",
            "Epoch [47/50], Batch 9, Loss: 0.3131\n",
            "Epoch [47/50], Batch 10, Loss: 0.1812\n",
            "Epoch [47/50], Batch 11, Loss: 0.1874\n",
            "Epoch [47/50], Batch 12, Loss: 0.2017\n",
            "Epoch [47/50], Batch 13, Loss: 0.1295\n",
            "Epoch [47/50], Batch 14, Loss: 0.2496\n",
            "Epoch [47/50], Batch 15, Loss: 0.2205\n",
            "Epoch [47/50], Batch 16, Loss: 0.2285\n",
            "Epoch [47/50], Batch 17, Loss: 0.1946\n",
            "Epoch [47/50], Batch 18, Loss: 0.2850\n",
            "Epoch [47/50], Batch 19, Loss: 0.1360\n",
            "Epoch [47/50], Batch 20, Loss: 0.1462\n",
            "Epoch [47/50], Batch 21, Loss: 0.1585\n",
            "Epoch [47/50], Batch 22, Loss: 0.2080\n",
            "Epoch [47/50], Batch 23, Loss: 0.1102\n",
            "Epoch [47/50], Batch 24, Loss: 0.2258\n",
            "Epoch [47/50], Batch 25, Loss: 0.1376\n",
            "Epoch [47/50], Batch 26, Loss: 0.1451\n",
            "Epoch [47/50], Batch 27, Loss: 0.2110\n",
            "Epoch [47/50], Batch 28, Loss: 0.2515\n",
            "Epoch [47/50], Batch 29, Loss: 0.2628\n",
            "Epoch [47/50], Batch 30, Loss: 0.0627\n",
            "Epoch [47/50], Batch 31, Loss: 0.1102\n",
            "Epoch [47/50], Batch 32, Loss: 0.1414\n",
            "Epoch [47/50], Batch 33, Loss: 0.1134\n",
            "Epoch [47/50], Batch 34, Loss: 0.1770\n",
            "Epoch [47/50], Batch 35, Loss: 0.1647\n",
            "Epoch [47/50], Batch 36, Loss: 0.1484\n",
            "Epoch [47/50], Batch 37, Loss: 0.1319\n",
            "Epoch [47/50], Batch 38, Loss: 0.1106\n",
            "Epoch [47/50], Batch 39, Loss: 0.1491\n",
            "Epoch [47/50], Batch 40, Loss: 0.1622\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [48/50], Batch 1, Loss: 0.1605\n",
            "Epoch [48/50], Batch 2, Loss: 0.1149\n",
            "Epoch [48/50], Batch 3, Loss: 0.0830\n",
            "Epoch [48/50], Batch 4, Loss: 0.0695\n",
            "Epoch [48/50], Batch 5, Loss: 0.1524\n",
            "Epoch [48/50], Batch 6, Loss: 0.1067\n",
            "Epoch [48/50], Batch 7, Loss: 0.1704\n",
            "Epoch [48/50], Batch 8, Loss: 0.1362\n",
            "Epoch [48/50], Batch 9, Loss: 0.1538\n",
            "Epoch [48/50], Batch 10, Loss: 0.1421\n",
            "Epoch [48/50], Batch 11, Loss: 0.1093\n",
            "Epoch [48/50], Batch 12, Loss: 0.1513\n",
            "Epoch [48/50], Batch 13, Loss: 0.1023\n",
            "Epoch [48/50], Batch 14, Loss: 0.1578\n",
            "Epoch [48/50], Batch 15, Loss: 0.1193\n",
            "Epoch [48/50], Batch 16, Loss: 0.1741\n",
            "Epoch [48/50], Batch 17, Loss: 0.0810\n",
            "Epoch [48/50], Batch 18, Loss: 0.0972\n",
            "Epoch [48/50], Batch 19, Loss: 0.1233\n",
            "Epoch [48/50], Batch 20, Loss: 0.1465\n",
            "Epoch [48/50], Batch 21, Loss: 0.1200\n",
            "Epoch [48/50], Batch 22, Loss: 0.0519\n",
            "Epoch [48/50], Batch 23, Loss: 0.2116\n",
            "Epoch [48/50], Batch 24, Loss: 0.0813\n",
            "Epoch [48/50], Batch 25, Loss: 0.1486\n",
            "Epoch [48/50], Batch 26, Loss: 0.0943\n",
            "Epoch [48/50], Batch 27, Loss: 0.2090\n",
            "Epoch [48/50], Batch 28, Loss: 0.0770\n",
            "Epoch [48/50], Batch 29, Loss: 0.1128\n",
            "Epoch [48/50], Batch 30, Loss: 0.1838\n",
            "Epoch [48/50], Batch 31, Loss: 0.1975\n",
            "Epoch [48/50], Batch 32, Loss: 0.1379\n",
            "Epoch [48/50], Batch 33, Loss: 0.0790\n",
            "Epoch [48/50], Batch 34, Loss: 0.2893\n",
            "Epoch [48/50], Batch 35, Loss: 0.1291\n",
            "Epoch [48/50], Batch 36, Loss: 0.1613\n",
            "Epoch [48/50], Batch 37, Loss: 0.0923\n",
            "Epoch [48/50], Batch 38, Loss: 0.0955\n",
            "Epoch [48/50], Batch 39, Loss: 0.4654\n",
            "Epoch [48/50], Batch 40, Loss: 0.1434\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [49/50], Batch 1, Loss: 0.2472\n",
            "Epoch [49/50], Batch 2, Loss: 0.1514\n",
            "Epoch [49/50], Batch 3, Loss: 0.1372\n",
            "Epoch [49/50], Batch 4, Loss: 0.1570\n",
            "Epoch [49/50], Batch 5, Loss: 0.0731\n",
            "Epoch [49/50], Batch 6, Loss: 0.1774\n",
            "Epoch [49/50], Batch 7, Loss: 0.1508\n",
            "Epoch [49/50], Batch 8, Loss: 0.0692\n",
            "Epoch [49/50], Batch 9, Loss: 0.0801\n",
            "Epoch [49/50], Batch 10, Loss: 0.1813\n",
            "Epoch [49/50], Batch 11, Loss: 0.0978\n",
            "Epoch [49/50], Batch 12, Loss: 0.1733\n",
            "Epoch [49/50], Batch 13, Loss: 0.1750\n",
            "Epoch [49/50], Batch 14, Loss: 0.1610\n",
            "Epoch [49/50], Batch 15, Loss: 0.1375\n",
            "Epoch [49/50], Batch 16, Loss: 0.1710\n",
            "Epoch [49/50], Batch 17, Loss: 0.0819\n",
            "Epoch [49/50], Batch 18, Loss: 0.1601\n",
            "Epoch [49/50], Batch 19, Loss: 0.1502\n",
            "Epoch [49/50], Batch 20, Loss: 0.1262\n",
            "Epoch [49/50], Batch 21, Loss: 0.1738\n",
            "Epoch [49/50], Batch 22, Loss: 0.1470\n",
            "Epoch [49/50], Batch 23, Loss: 0.1218\n",
            "Epoch [49/50], Batch 24, Loss: 0.1813\n",
            "Epoch [49/50], Batch 25, Loss: 0.1318\n",
            "Epoch [49/50], Batch 26, Loss: 0.1359\n",
            "Epoch [49/50], Batch 27, Loss: 0.2279\n",
            "Epoch [49/50], Batch 28, Loss: 0.1275\n",
            "Epoch [49/50], Batch 29, Loss: 0.1205\n",
            "Epoch [49/50], Batch 30, Loss: 0.1512\n",
            "Epoch [49/50], Batch 31, Loss: 0.1777\n",
            "Epoch [49/50], Batch 32, Loss: 0.1771\n",
            "Epoch [49/50], Batch 33, Loss: 0.1226\n",
            "Epoch [49/50], Batch 34, Loss: 0.1268\n",
            "Epoch [49/50], Batch 35, Loss: 0.2315\n",
            "Epoch [49/50], Batch 36, Loss: 0.1770\n",
            "Epoch [49/50], Batch 37, Loss: 0.1634\n",
            "Epoch [49/50], Batch 38, Loss: 0.0714\n",
            "Epoch [49/50], Batch 39, Loss: 0.1674\n",
            "Epoch [49/50], Batch 40, Loss: 0.1146\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch [50/50], Batch 1, Loss: 0.1132\n",
            "Epoch [50/50], Batch 2, Loss: 0.2361\n",
            "Epoch [50/50], Batch 3, Loss: 0.0474\n",
            "Epoch [50/50], Batch 4, Loss: 0.0791\n",
            "Epoch [50/50], Batch 5, Loss: 0.1201\n",
            "Epoch [50/50], Batch 6, Loss: 0.0957\n",
            "Epoch [50/50], Batch 7, Loss: 0.1970\n",
            "Epoch [50/50], Batch 8, Loss: 0.1345\n",
            "Epoch [50/50], Batch 9, Loss: 0.1651\n",
            "Epoch [50/50], Batch 10, Loss: 0.1126\n",
            "Epoch [50/50], Batch 11, Loss: 0.1358\n",
            "Epoch [50/50], Batch 12, Loss: 0.1500\n",
            "Epoch [50/50], Batch 13, Loss: 0.1349\n",
            "Epoch [50/50], Batch 14, Loss: 0.1201\n",
            "Epoch [50/50], Batch 15, Loss: 0.0560\n",
            "Epoch [50/50], Batch 16, Loss: 0.1797\n",
            "Epoch [50/50], Batch 17, Loss: 0.1373\n",
            "Epoch [50/50], Batch 18, Loss: 0.1280\n",
            "Epoch [50/50], Batch 19, Loss: 0.1037\n",
            "Epoch [50/50], Batch 20, Loss: 0.0727\n",
            "Epoch [50/50], Batch 21, Loss: 0.2244\n",
            "Epoch [50/50], Batch 22, Loss: 0.0817\n",
            "Epoch [50/50], Batch 23, Loss: 0.1228\n",
            "Epoch [50/50], Batch 24, Loss: 0.2668\n",
            "Epoch [50/50], Batch 25, Loss: 0.2131\n",
            "Epoch [50/50], Batch 26, Loss: 0.1479\n",
            "Epoch [50/50], Batch 27, Loss: 0.3621\n",
            "Epoch [50/50], Batch 28, Loss: 0.1487\n",
            "Epoch [50/50], Batch 29, Loss: 0.7072\n",
            "Epoch [50/50], Batch 30, Loss: 0.1971\n",
            "Epoch [50/50], Batch 31, Loss: 0.1692\n",
            "Epoch [50/50], Batch 32, Loss: 0.1861\n",
            "Epoch [50/50], Batch 33, Loss: 0.2314\n",
            "Epoch [50/50], Batch 34, Loss: 0.3835\n",
            "Epoch [50/50], Batch 35, Loss: 0.2110\n",
            "Epoch [50/50], Batch 36, Loss: 0.0896\n",
            "Epoch [50/50], Batch 37, Loss: 0.1981\n",
            "Epoch [50/50], Batch 38, Loss: 0.2373\n",
            "Epoch [50/50], Batch 39, Loss: 0.2386\n",
            "Epoch [50/50], Batch 40, Loss: 0.3043\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += batch_y.size(0)\n",
        "        n_correct += (predicted == batch_y.squeeze(1)).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 1000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vYMZxVf3y-0",
        "outputId": "20cc11b8-3a83-41ad-c19b-af0bf293ff2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1000 test images: 82.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIeyQFNgEIGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Applying this ANN in complete data**"
      ],
      "metadata": {
        "id": "QXd_ShBjXCDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from keras import datasets\n",
        "torch.manual_seed(7)\n",
        "\n",
        "\n",
        "# load dataset\n",
        "(X_train, y_train), (X_test, y_test) =datasets.fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "# Reshape the arrays to be 2-dimensional\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "y_train = y_train.reshape(y_train.shape[0], -1)\n",
        "y_test = y_test.reshape(y_test.shape[0], -1)\n",
        "\n",
        "# convert into Dataframe\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "\n",
        "# convert into tensors\n",
        "X_train_t = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# dataset and dataloader\n",
        "class custom_dataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "    self.n_samples=X.shape[0]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.X[index],self.y[index]\n",
        "\n",
        "train_dataset=custom_dataset(X_train_t,y_train_t)\n",
        "test_dataset=custom_dataset(X_test_t,y_test_t)\n",
        "\n",
        "train_loader=DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader=DataLoader(dataset=test_dataset,batch_size=32,shuffle=False)\n",
        "\n",
        "# Define model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.model=nn.Sequential(\n",
        "            nn.Linear(input_size,hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size,hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size,output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 128\n",
        "output_size = 10  # 10 classes for Fashion MNIST\n",
        "num_epochs = 50\n",
        "lr = 0.001\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "print(summary(model))\n",
        "\n",
        "# Training (one batch of dataset per epoch)\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss=0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        # forward pass\n",
        "        outputs = model(batch_X)\n",
        "        # loss calculation\n",
        "        l = loss(outputs, batch_y.squeeze(1))\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        # updating grads\n",
        "        optimizer.step()\n",
        "        total_loss+=l.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    print(\"=\"*65)\n",
        "\n",
        "\n",
        "# testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += batch_y.size(0)\n",
        "        n_correct += (predicted == batch_y.squeeze(1)).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 1000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rXCN6kfEIB2",
        "outputId": "4a0d7ef8-ecca-494c-8733-8d9ad61df01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "SimpleNN                                 --\n",
            "├─Sequential: 1-1                        --\n",
            "│    └─Linear: 2-1                       100,480\n",
            "│    └─ReLU: 2-2                         --\n",
            "│    └─Linear: 2-3                       16,512\n",
            "│    └─ReLU: 2-4                         --\n",
            "│    └─Linear: 2-5                       1,290\n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Epoch [1/50], Loss: 0.6414\n",
            "=================================================================\n",
            "Epoch [2/50], Loss: 0.4469\n",
            "=================================================================\n",
            "Epoch [3/50], Loss: 0.4136\n",
            "=================================================================\n",
            "Epoch [4/50], Loss: 0.3947\n",
            "=================================================================\n",
            "Epoch [5/50], Loss: 0.3823\n",
            "=================================================================\n",
            "Epoch [6/50], Loss: 0.3734\n",
            "=================================================================\n",
            "Epoch [7/50], Loss: 0.3610\n",
            "=================================================================\n",
            "Epoch [8/50], Loss: 0.3565\n",
            "=================================================================\n",
            "Epoch [9/50], Loss: 0.3482\n",
            "=================================================================\n",
            "Epoch [10/50], Loss: 0.3463\n",
            "=================================================================\n",
            "Epoch [11/50], Loss: 0.3421\n",
            "=================================================================\n",
            "Epoch [12/50], Loss: 0.3380\n",
            "=================================================================\n",
            "Epoch [13/50], Loss: 0.3285\n",
            "=================================================================\n",
            "Epoch [14/50], Loss: 0.3334\n",
            "=================================================================\n",
            "Epoch [15/50], Loss: 0.3259\n",
            "=================================================================\n",
            "Epoch [16/50], Loss: 0.3214\n",
            "=================================================================\n",
            "Epoch [17/50], Loss: 0.3229\n",
            "=================================================================\n",
            "Epoch [18/50], Loss: 0.3163\n",
            "=================================================================\n",
            "Epoch [19/50], Loss: 0.3180\n",
            "=================================================================\n",
            "Epoch [20/50], Loss: 0.3167\n",
            "=================================================================\n",
            "Epoch [21/50], Loss: 0.3183\n",
            "=================================================================\n",
            "Epoch [22/50], Loss: 0.3121\n",
            "=================================================================\n",
            "Epoch [23/50], Loss: 0.3071\n",
            "=================================================================\n",
            "Epoch [24/50], Loss: 0.3034\n",
            "=================================================================\n",
            "Epoch [25/50], Loss: 0.3050\n",
            "=================================================================\n",
            "Epoch [26/50], Loss: 0.3033\n",
            "=================================================================\n",
            "Epoch [27/50], Loss: 0.3051\n",
            "=================================================================\n",
            "Epoch [28/50], Loss: 0.3028\n",
            "=================================================================\n",
            "Epoch [29/50], Loss: 0.2991\n",
            "=================================================================\n",
            "Epoch [30/50], Loss: 0.3015\n",
            "=================================================================\n",
            "Epoch [31/50], Loss: 0.2986\n",
            "=================================================================\n",
            "Epoch [32/50], Loss: 0.2941\n",
            "=================================================================\n",
            "Epoch [33/50], Loss: 0.2998\n",
            "=================================================================\n",
            "Epoch [34/50], Loss: 0.2933\n",
            "=================================================================\n",
            "Epoch [35/50], Loss: 0.2977\n",
            "=================================================================\n",
            "Epoch [36/50], Loss: 0.2913\n",
            "=================================================================\n",
            "Epoch [37/50], Loss: 0.3015\n",
            "=================================================================\n",
            "Epoch [38/50], Loss: 0.2918\n",
            "=================================================================\n",
            "Epoch [39/50], Loss: 0.2936\n",
            "=================================================================\n",
            "Epoch [40/50], Loss: 0.3015\n",
            "=================================================================\n",
            "Epoch [41/50], Loss: 0.2962\n",
            "=================================================================\n",
            "Epoch [42/50], Loss: 0.2935\n",
            "=================================================================\n",
            "Epoch [43/50], Loss: 0.2860\n",
            "=================================================================\n",
            "Epoch [44/50], Loss: 0.2981\n",
            "=================================================================\n",
            "Epoch [45/50], Loss: 0.3011\n",
            "=================================================================\n",
            "Epoch [46/50], Loss: 0.2791\n",
            "=================================================================\n",
            "Epoch [47/50], Loss: 0.2936\n",
            "=================================================================\n",
            "Epoch [48/50], Loss: 0.2941\n",
            "=================================================================\n",
            "Epoch [49/50], Loss: 0.2926\n",
            "=================================================================\n",
            "Epoch [50/50], Loss: 0.2838\n",
            "=================================================================\n",
            "Accuracy of the network on the 1000 test images: 86.91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jm1JyInVEH8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using GPU to Speedup Process**"
      ],
      "metadata": {
        "id": "wNoi_b1WXNxz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrU304VjXNg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}